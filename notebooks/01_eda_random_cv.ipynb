{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073b64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2adc629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: e:\\GitHub\\Mini-Projects\\secom-yield-monitoring\\notebooks\n",
      "X shape: (1567, 590)\n",
      "L shape: (1567, 2)\n",
      "Row counts match: True\n",
      "Feature count: 590\n",
      "Unique labels: [-1, 1]\n",
      "Label counts:\n",
      " y\n",
      "-1    1463\n",
      " 1     104\n",
      "Name: count, dtype: int64\n",
      "Timestamp parse success: 1.0\n",
      "Head labels+time:\n",
      "    y           timestamp\n",
      "0 -1 2008-07-19 11:55:00\n",
      "1 -1 2008-07-19 12:32:00\n",
      "2  1 2008-07-19 13:17:00\n",
      "3 -1 2008-07-19 14:43:00\n",
      "4 -1 2008-07-19 15:22:00\n"
     ]
    }
   ],
   "source": [
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"data\" / \"raw\" / \"secom.data\").exists():\n",
    "    ROOT = ROOT.parent  # handles running from notebooks/\n",
    "\n",
    "x_path = ROOT / \"data\" / \"raw\" / \"secom.data\"\n",
    "y_path = ROOT / \"data\" / \"raw\" / \"secom_labels.data\"\n",
    "\n",
    "X = pd.read_csv(x_path, sep=r\"\\s+\", header=None, na_values=[\"NaN\", \"nan\"])\n",
    "L = pd.read_csv(y_path, sep=r\"\\s+\", header=None)\n",
    "\n",
    "# Handle label/timestamp format variants\n",
    "if L.shape[1] == 3:\n",
    "    L.columns = [\"y\", \"date\", \"time\"]\n",
    "    L[\"timestamp\"] = pd.to_datetime(L[\"date\"] + \" \" + L[\"time\"], errors=\"coerce\")\n",
    "elif L.shape[1] == 2:\n",
    "    L.columns = [\"y\", \"timestamp\"]\n",
    "    L[\"timestamp\"] = pd.to_datetime(L[\"timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected label file shape: {L.shape}\")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"L shape:\", L.shape)\n",
    "print(\"Row counts match:\", len(X) == len(L))\n",
    "print(\"Feature count:\", X.shape[1])\n",
    "print(\"Unique labels:\", sorted(L[\"y\"].dropna().unique().tolist()))\n",
    "print(\"Label counts:\\n\", L[\"y\"].value_counts(dropna=False))\n",
    "print(\"Timestamp parse success:\", L[\"timestamp\"].notna().mean())\n",
    "print(\"Head labels+time:\\n\", L[[\"y\", \"timestamp\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ecb1fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness summary:\n",
      "count    590.000000\n",
      "mean       0.045375\n",
      "std        0.154340\n",
      "min        0.000000\n",
      "25%        0.001276\n",
      "50%        0.003829\n",
      "75%        0.005743\n",
      "max        0.911934\n",
      "dtype: float64\n",
      "cols with >20% missing: 32\n",
      "cols with >40% missing: 32\n",
      "cols with >60% missing: 24\n",
      "cols with >80% missing: 8\n",
      "cols with >95% missing: 0\n",
      "\n",
      "Top 15 features where missingness differs by class:\n",
      "72     0.171960\n",
      "73     0.171960\n",
      "345    0.171960\n",
      "346    0.171960\n",
      "385    0.148858\n",
      "112    0.148858\n",
      "519    0.148858\n",
      "247    0.148858\n",
      "111    0.066289\n",
      "109    0.066289\n",
      "382    0.066289\n",
      "110    0.066289\n",
      "516    0.066289\n",
      "244    0.066289\n",
      "246    0.066289\n",
      "Name: delta_fail_minus_pass, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = (L[\"y\"] == 1).astype(int)  # 1=fail, 0=pass\n",
    "\n",
    "miss = X.isna().mean()\n",
    "print(\"Missingness summary:\")\n",
    "print(miss.describe())\n",
    "\n",
    "for t in [0.2, 0.4, 0.6, 0.8, 0.95]:\n",
    "    print(f\"cols with >{int(t*100)}% missing: {(miss > t).sum()}\")\n",
    "\n",
    "miss_by_class = pd.DataFrame({\n",
    "    \"pass_missing\": X[y == 0].isna().mean(),\n",
    "    \"fail_missing\": X[y == 1].isna().mean(),\n",
    "})\n",
    "miss_by_class[\"delta_fail_minus_pass\"] = miss_by_class[\"fail_missing\"] - miss_by_class[\"pass_missing\"]\n",
    "\n",
    "print(\"\\nTop 15 features where missingness differs by class:\")\n",
    "print(\n",
    "    miss_by_class[\"delta_fail_minus_pass\"]\n",
    "    .abs()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7186689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time range: 2008-07-19 11:55:00 -> 2008-10-17 06:07:00\n",
      "\n",
      "weekly fail-rate summary:\n",
      "count    14.000000\n",
      "mean      0.087106\n",
      "std       0.069633\n",
      "min       0.010638\n",
      "25%       0.034706\n",
      "50%       0.073364\n",
      "75%       0.123665\n",
      "max       0.230769\n",
      "Name: fail_rate, dtype: float64\n",
      "\n",
      "Top 10 highest-fail weeks:\n",
      "            count  fails  fail_rate\n",
      "timestamp                          \n",
      "2008-07-20     13      3   0.230769\n",
      "2008-08-03     48     10   0.208333\n",
      "2008-08-17     51      7   0.137255\n",
      "2008-08-10    108     14   0.129630\n",
      "2008-08-24    208     22   0.105769\n",
      "2008-07-27     21      2   0.095238\n",
      "2008-10-05    169     15   0.088757\n",
      "2008-10-12    138      8   0.057971\n",
      "2008-09-14     95      4   0.042105\n",
      "2008-08-31    169      7   0.041420\n",
      "\n",
      "Top 10 lowest-fail weeks:\n",
      "            count  fails  fail_rate\n",
      "timestamp                          \n",
      "2008-10-19     94      1   0.010638\n",
      "2008-09-07    133      2   0.015038\n",
      "2008-09-28    166      4   0.024096\n",
      "2008-09-21    154      5   0.032468\n",
      "2008-08-31    169      7   0.041420\n",
      "2008-09-14     95      4   0.042105\n",
      "2008-10-12    138      8   0.057971\n",
      "2008-10-05    169     15   0.088757\n",
      "2008-07-27     21      2   0.095238\n",
      "2008-08-24    208     22   0.105769\n"
     ]
    }
   ],
   "source": [
    "df = L.copy()\n",
    "df[\"fail\"] = (df[\"y\"] == 1).astype(int)\n",
    "df = df.sort_values(\"timestamp\")\n",
    "\n",
    "print(\"time range:\", df[\"timestamp\"].min(), \"->\", df[\"timestamp\"].max())\n",
    "\n",
    "weekly = (\n",
    "    df.set_index(\"timestamp\")[\"fail\"]\n",
    "      .resample(\"W\")\n",
    "      .agg([\"count\", \"sum\"])\n",
    "      .rename(columns={\"sum\": \"fails\"})\n",
    ") # type: ignore\n",
    "weekly[\"fail_rate\"] = weekly[\"fails\"] / weekly[\"count\"]\n",
    "\n",
    "print(\"\\nweekly fail-rate summary:\")\n",
    "print(weekly[\"fail_rate\"].describe())\n",
    "\n",
    "print(\"\\nTop 10 highest-fail weeks:\")\n",
    "print(weekly.sort_values(\"fail_rate\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop 10 lowest-fail weeks:\")\n",
    "print(weekly.sort_values(\"fail_rate\", ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a71eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant features: 116\n",
      "near-constant (>=99.5% same value): 122\n",
      "\n",
      "# pairs with |corr| >= 0.95: 316\n",
      "# pairs with |corr| >= 0.90: 397\n",
      "\n",
      "Top 20 absolute-correlation pairs:\n",
      "209  347    1.000000\n",
      "     342    1.000000\n",
      "     478    1.000000\n",
      "74   478    1.000000\n",
      "     209    1.000000\n",
      "     342    1.000000\n",
      "     347    1.000000\n",
      "342  347    1.000000\n",
      "347  478    1.000000\n",
      "206  209    1.000000\n",
      "     347    1.000000\n",
      "     478    1.000000\n",
      "74   206    1.000000\n",
      "206  342    1.000000\n",
      "342  478    1.000000\n",
      "34   36     1.000000\n",
      "140  275    1.000000\n",
      "172  174    1.000000\n",
      "307  309    0.999999\n",
      "152  287    0.999997\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# X already loaded\n",
    "n = len(X)\n",
    "\n",
    "# 1) Constant / near-constant\n",
    "nunique = X.nunique(dropna=True)\n",
    "const_cols = nunique[nunique <= 1].index.tolist()\n",
    "\n",
    "# near-constant by dominant value frequency (ignoring NaN)\n",
    "dom_frac = X.apply(lambda s: s.value_counts(dropna=True, normalize=True).iloc[0] if s.notna().any() else 1.0)\n",
    "near_const_cols = dom_frac[dom_frac >= 0.995].index.tolist()\n",
    "\n",
    "print(\"constant features:\", len(const_cols))\n",
    "print(\"near-constant (>=99.5% same value):\", len(near_const_cols))\n",
    "\n",
    "# 2) Correlation redundancy (after median impute only for this audit)\n",
    "Xi = X.copy()\n",
    "Xi = Xi.fillna(Xi.median(numeric_only=True))\n",
    "\n",
    "corr = Xi.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "high_corr_pairs = (upper.stack().sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n# pairs with |corr| >= 0.95:\", int((high_corr_pairs >= 0.95).sum()))\n",
    "print(\"# pairs with |corr| >= 0.90:\", int((high_corr_pairs >= 0.90).sum()))\n",
    "print(\"\\nTop 20 absolute-correlation pairs:\")\n",
    "print(high_corr_pairs.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bde467e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_const: 116\n",
      "drop_near_const: 122\n",
      "duplicate_components: 10\n",
      "drop_from_duplicates: 12\n",
      "final_keep_count: 456\n"
     ]
    }
   ],
   "source": [
    "y_bin = (L[\"y\"] == 1).astype(int)\n",
    "\n",
    "# base masks\n",
    "miss = X.isna().mean()\n",
    "dom = X.apply(lambda s: s.value_counts(dropna=True, normalize=True).iloc[0] if s.notna().any() else 1.0)\n",
    "nunique = X.nunique(dropna=True)\n",
    "\n",
    "drop_const = set(X.columns[nunique <= 1])\n",
    "drop_near_const = set(X.columns[dom >= 0.995])\n",
    "\n",
    "base_keep = [c for c in X.columns if c not in drop_const and c not in drop_near_const]\n",
    "Xi = X[base_keep].copy().fillna(X[base_keep].median())\n",
    "\n",
    "# high-corr duplicate graph\n",
    "corr = Xi.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "pairs = upper.stack()\n",
    "dup_pairs = pairs[pairs >= 0.9999].reset_index()\n",
    "dup_pairs.columns = [\"a\", \"b\", \"abs_corr\"]\n",
    "\n",
    "# adjacency\n",
    "adj = {c: set() for c in Xi.columns}\n",
    "for a, b, _ in dup_pairs.itertuples(index=False):\n",
    "    adj[a].add(b)\n",
    "    adj[b].add(a)\n",
    "\n",
    "# connected components\n",
    "seen, comps = set(), []\n",
    "for n in Xi.columns:\n",
    "    if n in seen or not adj[n]:\n",
    "        continue\n",
    "    stack, comp = [n], set()\n",
    "    while stack:\n",
    "        v = stack.pop()\n",
    "        if v in seen:\n",
    "            continue\n",
    "        seen.add(v)\n",
    "        comp.add(v)\n",
    "        stack.extend(adj[v] - seen)\n",
    "    comps.append(comp)\n",
    "\n",
    "# representative chooser\n",
    "var = Xi.var()\n",
    "yc = y_bin - y_bin.mean()\n",
    "rep_keep, rep_drop = set(), set()\n",
    "\n",
    "for comp in comps:\n",
    "    comp = list(comp)\n",
    "    # rank: lower missing, then higher variance, then higher |corr with y|\n",
    "    cxy = {}\n",
    "    for c in comp:\n",
    "        xc = Xi[c] - Xi[c].mean()\n",
    "        cxy[c] = abs((xc @ yc) / (np.linalg.norm(xc) * np.linalg.norm(yc) + 1e-12))\n",
    "    best = sorted(comp, key=lambda c: (miss[c], -var[c], -cxy[c]))[0]\n",
    "    rep_keep.add(best)\n",
    "    rep_drop.update(set(comp) - {best})\n",
    "\n",
    "final_drop = drop_const | drop_near_const | rep_drop\n",
    "final_keep = [c for c in X.columns if c not in final_drop]\n",
    "\n",
    "print(\"drop_const:\", len(drop_const))\n",
    "print(\"drop_near_const:\", len(drop_near_const))\n",
    "print(\"duplicate_components:\", len(comps))\n",
    "print(\"drop_from_duplicates:\", len(rep_drop))\n",
    "print(\"final_keep_count:\", len(final_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf0de395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, r_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42139322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "add_indicator=False\n",
      "BER      0.418409\n",
      "True+    0.269091\n",
      "True-    0.894092\n",
      "Name: mean, dtype: float64\n",
      "BER      0.092275\n",
      "True+    0.179234\n",
      "True-    0.022404\n",
      "Name: std, dtype: float64\n",
      "\n",
      "add_indicator=True\n",
      "BER      0.410133\n",
      "True+    0.289091\n",
      "True-    0.890644\n",
      "Name: mean, dtype: float64\n",
      "BER      0.081925\n",
      "True+    0.159130\n",
      "True-    0.018448\n",
      "Name: std, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_base = X[final_keep].copy()\n",
    "y_bin = (L[\"y\"] == 1).astype(int).values  # 1=fail, 0=pass\n",
    "\n",
    "def eval_baseline(add_indicator=True):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=add_indicator)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=42,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    rows = []\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)   # True+\n",
    "        tnr = tn / (tn + fp + 1e-12)   # True-\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(f\"\\nadd_indicator={add_indicator}\")\n",
    "    print(out[[\"BER\",\"True+\",\"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\",\"True+\",\"True-\"]].std().rename(\"std\"))\n",
    "    return out\n",
    "\n",
    "res_no_ind = eval_baseline(add_indicator=False)\n",
    "res_with_ind = eval_baseline(add_indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f80d07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER      0.365012\n",
      "True+    0.559091\n",
      "True-    0.710884\n",
      "Name: mean, dtype: float64\n",
      "BER      0.072750\n",
      "True+    0.134721\n",
      "True-    0.038923\n",
      "Name: std, dtype: float64\n",
      "\n",
      "Top selected transformed columns (frequency across folds):\n",
      "52     1.0\n",
      "93     1.0\n",
      "119    1.0\n",
      "25     1.0\n",
      "392    1.0\n",
      "114    1.0\n",
      "18     1.0\n",
      "258    1.0\n",
      "335    1.0\n",
      "244    1.0\n",
      "115    1.0\n",
      "101    1.0\n",
      "120    1.0\n",
      "112    1.0\n",
      "117    1.0\n",
      "281    0.9\n",
      "353    0.9\n",
      "165    0.9\n",
      "111    0.9\n",
      "520    0.8\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_base = X[final_keep].copy()\n",
    "y_bin = (L[\"y\"] == 1).astype(int).values\n",
    "\n",
    "class S2NSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, eps=1e-12):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        pos = X[y == 1]\n",
    "        neg = X[y == 0]\n",
    "\n",
    "        mu_pos = np.nanmean(pos, axis=0)\n",
    "        mu_neg = np.nanmean(neg, axis=0)\n",
    "        sd_pos = np.nanstd(pos, axis=0, ddof=0)\n",
    "        sd_neg = np.nanstd(neg, axis=0, ddof=0)\n",
    "\n",
    "        scores = np.abs(mu_pos - mu_neg) / (sd_pos + sd_neg + self.eps)\n",
    "        scores = np.nan_to_num(scores, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        self.scores_ = scores\n",
    "        self.idx_ = np.argsort(scores)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "def run_s2n(k=40):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"s2n\", S2NSelector(k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=42,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0,1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)\n",
    "        tnr = tn / (tn + fp + 1e-12)\n",
    "        ber = 1 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"s2n\"].idx_\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\",\"True+\",\"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\",\"True+\",\"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq\n",
    "\n",
    "res_s2n, freq_s2n = run_s2n(k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1824289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER      0.316597\n",
      "True+    0.665455\n",
      "True-    0.701351\n",
      "Name: mean, dtype: float64\n",
      "BER      0.091090\n",
      "True+    0.175486\n",
      "True-    0.032003\n",
      "Name: std, dtype: float64\n",
      "\n",
      "Top selected transformed columns (frequency across folds):\n",
      "52     1.0\n",
      "119    1.0\n",
      "93     0.9\n",
      "715    0.9\n",
      "801    0.8\n",
      "803    0.8\n",
      "714    0.8\n",
      "527    0.8\n",
      "528    0.8\n",
      "526    0.8\n",
      "717    0.8\n",
      "716    0.8\n",
      "800    0.8\n",
      "799    0.8\n",
      "636    0.8\n",
      "634    0.8\n",
      "633    0.8\n",
      "635    0.8\n",
      "524    0.8\n",
      "806    0.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# assumes these already exist from prior cells:\n",
    "# X_base = X[final_keep].copy()\n",
    "# y_bin = (L[\"y\"] == 1).astype(int).values\n",
    "\n",
    "class WelchTSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, eps=1e-12):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        pos = X[y == 1]\n",
    "        neg = X[y == 0]\n",
    "\n",
    "        m1 = np.mean(pos, axis=0)\n",
    "        m0 = np.mean(neg, axis=0)\n",
    "        v1 = np.var(pos, axis=0, ddof=1)\n",
    "        v0 = np.var(neg, axis=0, ddof=1)\n",
    "        n1 = max(pos.shape[0], 1)\n",
    "        n0 = max(neg.shape[0], 1)\n",
    "\n",
    "        t = np.abs(m1 - m0) / (np.sqrt(v1 / n1 + v0 / n0) + self.eps)\n",
    "        t = np.nan_to_num(t, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        self.scores_ = t\n",
    "        self.idx_ = np.argsort(t)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "def run_t(k=40, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"tsel\", WelchTSelector(k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "        tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"tsel\"].idx_\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "\n",
    "    return out, freq\n",
    "\n",
    "\n",
    "res_t, freq_t = run_t(k=40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6e6ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER      0.314160\n",
      "True+    0.616364\n",
      "True-    0.755316\n",
      "Name: mean, dtype: float64\n",
      "BER      0.057419\n",
      "True+    0.132906\n",
      "True-    0.043669\n",
      "Name: std, dtype: float64\n",
      "\n",
      "Top selected transformed columns (frequency across folds):\n",
      "18     1.0\n",
      "25     1.0\n",
      "93     1.0\n",
      "52     1.0\n",
      "334    1.0\n",
      "335    1.0\n",
      "151    1.0\n",
      "119    1.0\n",
      "340    1.0\n",
      "281    1.0\n",
      "244    1.0\n",
      "392    1.0\n",
      "186    1.0\n",
      "339    1.0\n",
      "338    1.0\n",
      "114    0.9\n",
      "241    0.9\n",
      "148    0.9\n",
      "111    0.9\n",
      "115    0.8\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def run_f(k=40, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"fsel\", SelectKBest(score_func=f_classif, k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    rows, selected_counts = [], {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)\n",
    "        tnr = tn / (tn + fp + 1e-12)\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"fsel\"].get_support(indices=True)\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq\n",
    "\n",
    "res_f, freq_f = run_f(k=40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b8ed4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER      0.314160\n",
      "True+    0.616364\n",
      "True-    0.755316\n",
      "Name: mean, dtype: float64\n",
      "BER      0.057419\n",
      "True+    0.132906\n",
      "True-    0.043669\n",
      "Name: std, dtype: float64\n",
      "\n",
      "Top selected transformed columns (frequency across folds):\n",
      "18     1.0\n",
      "25     1.0\n",
      "93     1.0\n",
      "52     1.0\n",
      "334    1.0\n",
      "335    1.0\n",
      "151    1.0\n",
      "119    1.0\n",
      "340    1.0\n",
      "281    1.0\n",
      "244    1.0\n",
      "392    1.0\n",
      "186    1.0\n",
      "339    1.0\n",
      "338    1.0\n",
      "114    0.9\n",
      "241    0.9\n",
      "148    0.9\n",
      "111    0.9\n",
      "115    0.8\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def run_pearson(k=40, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"psel\", SelectKBest(score_func=lambda X, y: np.abs(r_regression(X, y)), k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    rows, selected_counts = [], {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)\n",
    "        tnr = tn / (tn + fp + 1e-12)\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"psel\"].get_support(indices=True)\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq\n",
    "\n",
    "res_p, freq_p = run_pearson(k=40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bff6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same selected set: True\n",
      "Jaccard: 1.0\n"
     ]
    }
   ],
   "source": [
    "set_f = set(freq_f.index)\n",
    "set_p = set(freq_p.index)\n",
    "print(\"same selected set:\", set_f == set_p)\n",
    "print(\"Jaccard:\", len(set_f & set_p) / len(set_f | set_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcbe3999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER      0.305183\n",
      "True+    0.628182\n",
      "True-    0.761453\n",
      "Name: mean, dtype: float64\n",
      "BER      0.096087\n",
      "True+    0.171122\n",
      "True-    0.049545\n",
      "Name: std, dtype: float64\n",
      "\n",
      "Top selected transformed columns (frequency across folds):\n",
      "58     1.0\n",
      "311    1.0\n",
      "52     1.0\n",
      "405    1.0\n",
      "217    1.0\n",
      "57     1.0\n",
      "71     1.0\n",
      "218    1.0\n",
      "55     1.0\n",
      "406    1.0\n",
      "54     1.0\n",
      "93     1.0\n",
      "122    1.0\n",
      "281    1.0\n",
      "312    1.0\n",
      "59     1.0\n",
      "48     1.0\n",
      "356    1.0\n",
      "168    1.0\n",
      "62     0.9\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from skrebate import ReliefF\n",
    "\n",
    "class ReliefFSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, n_neighbors=10):\n",
    "        self.k = k\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        self.rf_ = ReliefF(\n",
    "            n_features_to_select=self.k,\n",
    "            n_neighbors=self.n_neighbors,\n",
    "        )\n",
    "        self.rf_.fit(X, y)\n",
    "\n",
    "        imp = np.asarray(self.rf_.feature_importances_, dtype=float)\n",
    "        imp = np.nan_to_num(imp, nan=-np.inf)\n",
    "        self.scores_ = imp\n",
    "        self.idx_ = np.argsort(imp)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "def run_relieff(k=40, n_neighbors=10, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"rsel\", ReliefFSelector(k=k, n_neighbors=n_neighbors)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "        tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"rsel\"].idx_\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "\n",
    "    return out, freq\n",
    "\n",
    "res_relief, freq_relief = run_relieff(k=40, n_neighbors=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "514e9556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER      0.393663\n",
      "True+    0.432727\n",
      "True-    0.779946\n",
      "Name: mean, dtype: float64\n",
      "BER      0.069747\n",
      "True+    0.131684\n",
      "True-    0.028437\n",
      "Name: std, dtype: float64\n",
      "\n",
      "Top selected transformed columns (frequency across folds):\n",
      "52     1.0\n",
      "18     1.0\n",
      "57     1.0\n",
      "341    1.0\n",
      "66     1.0\n",
      "89     1.0\n",
      "119    0.9\n",
      "104    0.9\n",
      "190    0.8\n",
      "282    0.8\n",
      "473    0.8\n",
      "143    0.8\n",
      "281    0.8\n",
      "501    0.7\n",
      "58     0.7\n",
      "441    0.7\n",
      "393    0.7\n",
      "11     0.7\n",
      "428    0.6\n",
      "111    0.6\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class GramSchmidtSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, eps=1e-12):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        n, p = X.shape\n",
    "        k = min(self.k, p)\n",
    "\n",
    "        # Work copies\n",
    "        Xw = X.copy()\n",
    "        r = y - y.mean()  # residual target direction\n",
    "\n",
    "        remaining = list(range(p))\n",
    "        selected = []\n",
    "        scores = []\n",
    "\n",
    "        for _ in range(k):\n",
    "            r_norm = np.linalg.norm(r)\n",
    "            if r_norm < self.eps or not remaining:\n",
    "                break\n",
    "\n",
    "            # score remaining features by absolute cosine with residual\n",
    "            best_j = None\n",
    "            best_score = -np.inf\n",
    "\n",
    "            for j in remaining:\n",
    "                xj = Xw[:, j]\n",
    "                x_norm = np.linalg.norm(xj)\n",
    "                if x_norm < self.eps:\n",
    "                    s = -np.inf\n",
    "                else:\n",
    "                    s = abs(np.dot(xj, r)) / (x_norm * r_norm + self.eps)\n",
    "\n",
    "                if s > best_score:\n",
    "                    best_score = s\n",
    "                    best_j = j\n",
    "\n",
    "            if best_j is None or not np.isfinite(best_score):\n",
    "                break\n",
    "\n",
    "            selected.append(best_j)\n",
    "            scores.append(best_score)\n",
    "\n",
    "            # orthonormal direction q of selected feature\n",
    "            q = Xw[:, best_j]\n",
    "            q_norm = np.linalg.norm(q)\n",
    "            if q_norm < self.eps:\n",
    "                remaining.remove(best_j)\n",
    "                continue\n",
    "            q = q / q_norm\n",
    "\n",
    "            # remove selected direction from residual and remaining features\n",
    "            r = r - np.dot(r, q) * q\n",
    "\n",
    "            for j in remaining:\n",
    "                if j == best_j:\n",
    "                    continue\n",
    "                Xw[:, j] = Xw[:, j] - np.dot(Xw[:, j], q) * q\n",
    "\n",
    "            remaining.remove(best_j)\n",
    "\n",
    "        self.idx_ = np.array(selected, dtype=int)\n",
    "        self.scores_ = np.array(scores, dtype=float)\n",
    "\n",
    "        # pad if early stop (rare)\n",
    "        if len(self.idx_) < k:\n",
    "            leftovers = [j for j in range(p) if j not in set(self.idx_)]\n",
    "            need = k - len(self.idx_)\n",
    "            self.idx_ = np.concatenate([self.idx_, np.array(leftovers[:need], dtype=int)])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "def run_gram_schmidt(k=40, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"gsel\", GramSchmidtSelector(k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "        tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"gsel\"].idx_\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "\n",
    "    return out, freq\n",
    "\n",
    "\n",
    "res_gs, freq_gs = run_gram_schmidt(k=40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94e95cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 (C=0.15, k=40)\n",
      "BER      0.417631\n",
      "True+    0.382727\n",
      "True-    0.782010\n",
      "Name: mean, dtype: float64\n",
      "BER      0.091526\n",
      "True+    0.176355\n",
      "True-    0.027663\n",
      "Name: std, dtype: float64\n",
      "\n",
      "Top selected transformed columns (frequency across folds):\n",
      "52     1.0\n",
      "119    1.0\n",
      "49     1.0\n",
      "57     1.0\n",
      "122    1.0\n",
      "89     1.0\n",
      "143    1.0\n",
      "190    1.0\n",
      "380    1.0\n",
      "18     0.9\n",
      "7      0.9\n",
      "228    0.9\n",
      "393    0.9\n",
      "66     0.8\n",
      "60     0.8\n",
      "121    0.8\n",
      "327    0.8\n",
      "120    0.8\n",
      "36     0.8\n",
      "101    0.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def _metrics_from_pred(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "    tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "    ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "    return ber, tpr, tnr\n",
    "\n",
    "\n",
    "def run_l1(k=40, C=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Embedded selection via L1 logistic.\n",
    "    Top-k selected each fold by |coef| (on preprocessed train fold).\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"saga\",\n",
    "            C=C,\n",
    "            l1_ratio=1.0,  # new sklearn style for pure L1\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=8000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "\n",
    "        # rank by absolute coefficient, keep top-k\n",
    "        coef = np.abs(pipe.named_steps[\"clf\"].coef_[0])\n",
    "        idx = np.argsort(coef)[::-1][:k]\n",
    "\n",
    "        # transform train/test through preprocessors only, then subset columns\n",
    "        Xtr_t = pipe[:-1].transform(Xtr)[:, idx]\n",
    "        Xte_t = pipe[:-1].transform(Xte)[:, idx]\n",
    "\n",
    "        # refit logistic on selected columns only\n",
    "        clf2 = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=4000,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        clf2.fit(Xtr_t, ytr)\n",
    "        pred = clf2.predict(Xte_t)\n",
    "\n",
    "        ber, tpr, tnr = _metrics_from_pred(yte, pred)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(f\"L1 (C={C}, k={k})\")\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq\n",
    "\n",
    "\n",
    "def run_elasticnet(k=40, C=0.15, l1_ratio=0.4, random_state=42):\n",
    "    \"\"\"\n",
    "    Embedded selection via Elastic Net logistic.\n",
    "    Top-k selected each fold by |coef| (on preprocessed train fold).\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"saga\",\n",
    "            C=C,\n",
    "            l1_ratio=l1_ratio,\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=8000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "\n",
    "        # rank by absolute coefficient, keep top-k\n",
    "        coef = np.abs(pipe.named_steps[\"clf\"].coef_[0])\n",
    "        idx = np.argsort(coef)[::-1][:k]\n",
    "\n",
    "        # transform train/test through preprocessors only, then subset columns\n",
    "        Xtr_t = pipe[:-1].transform(Xtr)[:, idx]\n",
    "        Xte_t = pipe[:-1].transform(Xte)[:, idx]\n",
    "\n",
    "        # refit logistic on selected columns only\n",
    "        clf2 = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=4000,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        clf2.fit(Xtr_t, ytr)\n",
    "        pred = clf2.predict(Xte_t)\n",
    "\n",
    "        ber, tpr, tnr = _metrics_from_pred(yte, pred)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(f\"Elastic Net (C={C}, l1_ratio={l1_ratio}, k={k})\")\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq\n",
    "\n",
    "# Example usage:\n",
    "res_l1, freq_l1 = run_l1(k=40, C=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdaf3249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net (C=0.15, l1_ratio=0.4, k=40)\n",
      "BER      0.402885\n",
      "True+    0.421818\n",
      "True-    0.772412\n",
      "Name: mean, dtype: float64\n",
      "BER      0.055037\n",
      "True+    0.117222\n",
      "True-    0.029515\n",
      "Name: std, dtype: float64\n",
      "\n",
      "Top selected transformed columns (frequency across folds):\n",
      "52     1.0\n",
      "49     1.0\n",
      "119    1.0\n",
      "122    1.0\n",
      "57     1.0\n",
      "143    1.0\n",
      "7      0.9\n",
      "36     0.9\n",
      "89     0.9\n",
      "210    0.9\n",
      "380    0.9\n",
      "299    0.9\n",
      "228    0.8\n",
      "60     0.8\n",
      "192    0.8\n",
      "297    0.8\n",
      "18     0.8\n",
      "393    0.8\n",
      "92     0.7\n",
      "121    0.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "res_en, freq_en = run_elasticnet(k=40, C=0.15, l1_ratio=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c976ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15818229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    method  BER_mean   BER_std  True+_mean  True+_std  True-_mean  True-_std  \\\n",
      "1  ReliefF  0.318685  0.072940    0.606909   0.151337    0.755721   0.039235   \n",
      "2  Welch-t  0.340504  0.078633    0.631636   0.155153    0.687356   0.046366   \n",
      "0   F-test  0.350492  0.067897    0.565455   0.135936    0.733562   0.036800   \n",
      "\n",
      "   mean_pairwise_jaccard  \n",
      "1               0.850505  \n",
      "2               0.845169  \n",
      "0               0.571730  \n",
      "\n",
      "Top selection frequency: ReliefF\n",
      "M447    1.0\n",
      "M445    1.0\n",
      "X281    1.0\n",
      "X93     1.0\n",
      "X48     1.0\n",
      "X52     1.0\n",
      "M65     1.0\n",
      "X311    1.0\n",
      "M279    1.0\n",
      "X57     1.0\n",
      "X405    1.0\n",
      "X58     1.0\n",
      "M446    1.0\n",
      "M208    1.0\n",
      "X312    1.0\n",
      "X217    1.0\n",
      "X55     1.0\n",
      "M64     1.0\n",
      "X218    1.0\n",
      "M280    1.0\n",
      "dtype: float64\n",
      "\n",
      "Top selection frequency: F-test\n",
      "X392    1.00\n",
      "X25     1.00\n",
      "X281    1.00\n",
      "X93     1.00\n",
      "X52     1.00\n",
      "X119    1.00\n",
      "X335    0.94\n",
      "X334    0.92\n",
      "X338    0.92\n",
      "X186    0.92\n",
      "X114    0.92\n",
      "X18     0.92\n",
      "X258    0.90\n",
      "X340    0.90\n",
      "X339    0.90\n",
      "M280    0.88\n",
      "X151    0.88\n",
      "X244    0.88\n",
      "M279    0.84\n",
      "X241    0.84\n",
      "dtype: float64\n",
      "\n",
      "Top selection frequency: Welch-t\n",
      "M73     1.00\n",
      "M68     1.00\n",
      "M71     1.00\n",
      "M70     1.00\n",
      "M69     1.00\n",
      "M379    0.98\n",
      "M380    0.98\n",
      "M191    0.98\n",
      "M402    0.98\n",
      "M381    0.98\n",
      "M72     0.98\n",
      "M192    0.98\n",
      "X52     0.98\n",
      "M190    0.96\n",
      "M376    0.96\n",
      "M288    0.96\n",
      "M285    0.96\n",
      "M186    0.96\n",
      "M66     0.96\n",
      "X119    0.96\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ---------- Selectors ----------\n",
    "class WelchTSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, eps=1e-12):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        pos = X[y == 1]\n",
    "        neg = X[y == 0]\n",
    "\n",
    "        m1 = np.mean(pos, axis=0)\n",
    "        m0 = np.mean(neg, axis=0)\n",
    "        v1 = np.var(pos, axis=0, ddof=1)\n",
    "        v0 = np.var(neg, axis=0, ddof=1)\n",
    "\n",
    "        n1 = max(pos.shape[0], 1)\n",
    "        n0 = max(neg.shape[0], 1)\n",
    "\n",
    "        t = np.abs(m1 - m0) / (np.sqrt(v1 / n1 + v0 / n0) + self.eps)\n",
    "        t = np.nan_to_num(t, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        self.idx_ = np.argsort(t)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "class ReliefFSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, n_neighbors=10):\n",
    "        self.k = k\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        self.rf_ = ReliefF(n_features_to_select=self.k, n_neighbors=self.n_neighbors)\n",
    "        self.rf_.fit(X, y)\n",
    "\n",
    "        imp = np.asarray(self.rf_.feature_importances_, dtype=float)\n",
    "        imp = np.nan_to_num(imp, nan=-np.inf)\n",
    "        self.idx_ = np.argsort(imp)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def ber_tpr_tnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "    tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "    ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "    return ber, tpr, tnr\n",
    "\n",
    "\n",
    "def selected_indices(selector):\n",
    "    if hasattr(selector, \"get_support\"):\n",
    "        return selector.get_support(indices=True)\n",
    "    return selector.idx_\n",
    "\n",
    "\n",
    "def selected_keys_from_pipe(pipe, selector_step, n_raw_features):\n",
    "    idx = selected_indices(pipe.named_steps[selector_step])\n",
    "    idx = np.asarray(idx, dtype=int)\n",
    "\n",
    "    imputer = pipe.named_steps[\"imputer\"]\n",
    "    miss_feats = []\n",
    "    if hasattr(imputer, \"indicator_\") and imputer.indicator_ is not None:\n",
    "        miss_feats = list(imputer.indicator_.features_)\n",
    "\n",
    "    keys = []\n",
    "    for j in idx:\n",
    "        if j < n_raw_features:\n",
    "            keys.append(f\"X{j}\")  # raw feature index in X_base\n",
    "        else:\n",
    "            off = j - n_raw_features\n",
    "            if 0 <= off < len(miss_feats):\n",
    "                keys.append(f\"M{int(miss_feats[off])}\")  # missing-indicator for raw feature\n",
    "            else:\n",
    "                keys.append(f\"UNK{j}\")\n",
    "    return set(keys)\n",
    "\n",
    "\n",
    "def mean_pairwise_jaccard(sets):\n",
    "    if len(sets) < 2:\n",
    "        return np.nan\n",
    "    vals = []\n",
    "    for a, b in combinations(sets, 2):\n",
    "        u = len(a | b)\n",
    "        vals.append(len(a & b) / u if u else 1.0)\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "\n",
    "# ---------- Main runner ----------\n",
    "def run_finalists_repeated(\n",
    "    X_base,\n",
    "    y_bin,\n",
    "    k=40,\n",
    "    seeds=(11, 22, 33, 44, 55),   # 5 repeats x 10 folds = 50 folds/method\n",
    "    relief_neighbors=10,\n",
    "):\n",
    "    methods = {\n",
    "        \"F-test\": (\"sel\", SelectKBest(score_func=f_classif, k=k)),\n",
    "        \"Welch-t\": (\"sel\", WelchTSelector(k=k)),\n",
    "        \"ReliefF\": (\"sel\", ReliefFSelector(k=k, n_neighbors=relief_neighbors)),\n",
    "    }\n",
    "\n",
    "    n_raw = X_base.shape[1]\n",
    "    rows = []\n",
    "    selected_sets = {m: [] for m in methods}\n",
    "    selected_counter = {m: Counter() for m in methods}\n",
    "\n",
    "    for method_name, (sel_name, sel_obj) in methods.items():\n",
    "        for seed in seeds:\n",
    "            cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "            for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "                Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "                ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "                pipe = Pipeline([\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (sel_name, sel_obj),\n",
    "                    (\"clf\", LogisticRegression(\n",
    "                        solver=\"lbfgs\",\n",
    "                        class_weight=\"balanced\",\n",
    "                        max_iter=3000,\n",
    "                        random_state=seed,\n",
    "                    )),\n",
    "                ])\n",
    "\n",
    "                pipe.fit(Xtr, ytr)\n",
    "                pred = pipe.predict(Xte)\n",
    "                ber, tpr, tnr = ber_tpr_tnr(yte, pred)\n",
    "\n",
    "                keys = selected_keys_from_pipe(pipe, sel_name, n_raw_features=n_raw)\n",
    "                selected_sets[method_name].append(keys)\n",
    "                selected_counter[method_name].update(keys)\n",
    "\n",
    "                rows.append({\n",
    "                    \"method\": method_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"fold\": fold,\n",
    "                    \"BER\": ber,\n",
    "                    \"True+\": tpr,\n",
    "                    \"True-\": tnr,\n",
    "                })\n",
    "\n",
    "    detail = pd.DataFrame(rows)\n",
    "\n",
    "    # summary\n",
    "    agg = (\n",
    "        detail.groupby(\"method\")[[\"BER\", \"True+\", \"True-\"]]\n",
    "        .agg([\"mean\", \"std\"])\n",
    "    )\n",
    "    agg.columns = [\"_\".join(c) for c in agg.columns]\n",
    "    agg = agg.reset_index()\n",
    "\n",
    "    agg[\"mean_pairwise_jaccard\"] = agg[\"method\"].map(\n",
    "        lambda m: mean_pairwise_jaccard(selected_sets[m])\n",
    "    )\n",
    "\n",
    "    # top selection frequency per method\n",
    "    total_runs = len(seeds) * 10\n",
    "    top_freq = {}\n",
    "    for m in methods:\n",
    "        s = pd.Series(selected_counter[m]).sort_values(ascending=False) / total_runs\n",
    "        top_freq[m] = s\n",
    "\n",
    "    return detail, agg.sort_values(\"BER_mean\"), top_freq\n",
    "\n",
    "\n",
    "# ---- Execute ----\n",
    "detail_df, summary_df, top_freq = run_finalists_repeated(\n",
    "    X_base=X_base,\n",
    "    y_bin=y_bin,\n",
    "    k=40,\n",
    "    seeds=(11, 22, 33, 44, 55),\n",
    "    relief_neighbors=10,\n",
    ")\n",
    "\n",
    "print(summary_df)\n",
    "\n",
    "for m in [\"ReliefF\", \"F-test\", \"Welch-t\"]:\n",
    "    print(f\"\\nTop selection frequency: {m}\")\n",
    "    print(top_freq[m].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8695f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>freq</th>\n",
       "      <th>kind</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>miss_fail</th>\n",
       "      <th>miss_pass</th>\n",
       "      <th>delta_fail_minus_pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M447</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing_indicator_for</td>\n",
       "      <td>581</td>\n",
       "      <td>0.567308</td>\n",
       "      <td>0.608339</td>\n",
       "      <td>-0.041031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing_indicator_for</td>\n",
       "      <td>579</td>\n",
       "      <td>0.567308</td>\n",
       "      <td>0.608339</td>\n",
       "      <td>-0.041031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing_indicator_for</td>\n",
       "      <td>73</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.518113</td>\n",
       "      <td>-0.171960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing_indicator_for</td>\n",
       "      <td>345</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.518113</td>\n",
       "      <td>-0.171960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing_indicator_for</td>\n",
       "      <td>580</td>\n",
       "      <td>0.567308</td>\n",
       "      <td>0.608339</td>\n",
       "      <td>-0.041031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing_indicator_for</td>\n",
       "      <td>247</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>-0.148858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing_indicator_for</td>\n",
       "      <td>72</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.518113</td>\n",
       "      <td>-0.171960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>value</td>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing_indicator_for</td>\n",
       "      <td>346</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.518113</td>\n",
       "      <td>-0.171960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key  freq                   kind  sensor_id  miss_fail  miss_pass  \\\n",
       "0   M447   1.0  missing_indicator_for        581   0.567308   0.608339   \n",
       "1   M445   1.0  missing_indicator_for        579   0.567308   0.608339   \n",
       "2   X281   1.0                  value        348        NaN        NaN   \n",
       "3    X93   1.0                  value        103        NaN        NaN   \n",
       "4    X48   1.0                  value         55        NaN        NaN   \n",
       "5    X52   1.0                  value         59        NaN        NaN   \n",
       "6    M65   1.0  missing_indicator_for         73   0.346154   0.518113   \n",
       "7   X311   1.0                  value        405        NaN        NaN   \n",
       "8   M279   1.0  missing_indicator_for        345   0.346154   0.518113   \n",
       "9    X57   1.0                  value         64        NaN        NaN   \n",
       "10  X405   1.0                  value        539        NaN        NaN   \n",
       "11   X58   1.0                  value         65        NaN        NaN   \n",
       "12  M446   1.0  missing_indicator_for        580   0.567308   0.608339   \n",
       "13  M208   1.0  missing_indicator_for        247   0.317308   0.466165   \n",
       "14  X312   1.0                  value        406        NaN        NaN   \n",
       "15  X217   1.0                  value        267        NaN        NaN   \n",
       "16   X55   1.0                  value         62        NaN        NaN   \n",
       "17   M64   1.0  missing_indicator_for         72   0.346154   0.518113   \n",
       "18  X218   1.0                  value        268        NaN        NaN   \n",
       "19  M280   1.0  missing_indicator_for        346   0.346154   0.518113   \n",
       "\n",
       "    delta_fail_minus_pass  \n",
       "0               -0.041031  \n",
       "1               -0.041031  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "5                     NaN  \n",
       "6               -0.171960  \n",
       "7                     NaN  \n",
       "8               -0.171960  \n",
       "9                     NaN  \n",
       "10                    NaN  \n",
       "11                    NaN  \n",
       "12              -0.041031  \n",
       "13              -0.148858  \n",
       "14                    NaN  \n",
       "15                    NaN  \n",
       "16                    NaN  \n",
       "17              -0.171960  \n",
       "18                    NaN  \n",
       "19              -0.171960  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode top_freq keys to original sensor IDs and inspect missingness effect\n",
    "raw_cols = list(X_base.columns)  # original feature IDs from SECOM after hygiene\n",
    "\n",
    "def decode_key(k):\n",
    "    kind = \"value\" if k.startswith(\"X\") else \"missing_indicator_for\"\n",
    "    idx = int(k[1:])\n",
    "    return kind, raw_cols[idx]\n",
    "\n",
    "def missing_delta_for_idx(idx):\n",
    "    col = raw_cols[idx]\n",
    "    miss_fail = X_base.loc[y_bin == 1, col].isna().mean()\n",
    "    miss_pass = X_base.loc[y_bin == 0, col].isna().mean()\n",
    "    return miss_fail, miss_pass, miss_fail - miss_pass\n",
    "\n",
    "top_relief = top_freq[\"ReliefF\"].head(20)\n",
    "rows = []\n",
    "for k, f in top_relief.items():\n",
    "    kind, sensor = decode_key(k)\n",
    "    if kind == \"missing_indicator_for\":\n",
    "        mf, mp, d = missing_delta_for_idx(int(k[1:]))\n",
    "    else:\n",
    "        mf = mp = d = np.nan\n",
    "    rows.append({\n",
    "        \"key\": k, \"freq\": f, \"kind\": kind, \"sensor_id\": sensor,\n",
    "        \"miss_fail\": mf, \"miss_pass\": mp, \"delta_fail_minus_pass\": d\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f803e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ReliefF mode=both\n",
      "BER      0.305183\n",
      "True+    0.628182\n",
      "True-    0.761453\n",
      "Name: mean, dtype: float64\n",
      "BER      0.096087\n",
      "True+    0.171122\n",
      "True-    0.049545\n",
      "Name: std, dtype: float64\n",
      "\n",
      "ReliefF mode=values\n",
      "BER      0.342262\n",
      "True+    0.571818\n",
      "True-    0.743659\n",
      "Name: mean, dtype: float64\n",
      "BER      0.096057\n",
      "True+    0.177393\n",
      "True-    0.043541\n",
      "Name: std, dtype: float64\n",
      "\n",
      "ReliefF mode=indicators\n",
      "BER      0.416490\n",
      "True+    0.549091\n",
      "True-    0.617929\n",
      "Name: mean, dtype: float64\n",
      "BER      0.060119\n",
      "True+    0.115804\n",
      "True-    0.043169\n",
      "Name: std, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def ber_tpr_tnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    tpr = tp / (tp + fn + 1e-12)\n",
    "    tnr = tn / (tn + fp + 1e-12)\n",
    "    ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "    return ber, tpr, tnr\n",
    "\n",
    "def run_relieff_ablation(mode=\"both\", k=40, n_neighbors=10, random_state=42):\n",
    "    # mode: \"both\", \"values\", \"indicators\"\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    rows = []\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        imp = SimpleImputer(strategy=\"median\", add_indicator=True)\n",
    "        Xtr_i = imp.fit_transform(Xtr)\n",
    "        Xte_i = imp.transform(Xte)\n",
    "\n",
    "        n_raw = Xtr.shape[1]\n",
    "        if mode == \"both\":\n",
    "            keep = np.arange(Xtr_i.shape[1])\n",
    "        elif mode == \"values\":\n",
    "            keep = np.arange(n_raw)\n",
    "        elif mode == \"indicators\":\n",
    "            keep = np.arange(n_raw, Xtr_i.shape[1])\n",
    "        else:\n",
    "            raise ValueError(\"mode must be one of: both, values, indicators\")\n",
    "\n",
    "        if len(keep) == 0:\n",
    "            raise ValueError(\"No columns available for this mode.\")\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        Xtr_s = sc.fit_transform(Xtr_i[:, keep])\n",
    "        Xte_s = sc.transform(Xte_i[:, keep])\n",
    "\n",
    "        k_use = min(k, Xtr_s.shape[1])\n",
    "        rf = ReliefF(n_features_to_select=k_use, n_neighbors=n_neighbors)\n",
    "        rf.fit(Xtr_s, ytr)\n",
    "        sel = np.argsort(rf.feature_importances_)[::-1][:k_use]\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        clf.fit(Xtr_s[:, sel], ytr)\n",
    "        pred = clf.predict(Xte_s[:, sel])\n",
    "\n",
    "        ber, tpr, tnr = ber_tpr_tnr(yte, pred)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(f\"\\nReliefF mode={mode}\")\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "    return out\n",
    "\n",
    "res_both = run_relieff_ablation(\"both\")\n",
    "res_val  = run_relieff_ablation(\"values\")\n",
    "res_miss = run_relieff_ablation(\"indicators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb68602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2008-07-19 11:55:00 -> 2008-09-26 02:26:00 n= 1096 fail_rate= 0.07116788321167883\n",
      "Test  range: 2008-09-26 03:12:00 -> 2008-10-17 06:07:00 n= 471 fail_rate= 0.055201698513800426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>BER</th>\n",
       "      <th>True+</th>\n",
       "      <th>True-</th>\n",
       "      <th>train_fail_rate</th>\n",
       "      <th>test_fail_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.460890</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.071168</td>\n",
       "      <td>0.055202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F-test</td>\n",
       "      <td>0.418064</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.856180</td>\n",
       "      <td>0.071168</td>\n",
       "      <td>0.055202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method       BER     True+     True-  train_fail_rate  test_fail_rate\n",
       "0  ReliefF  0.460890  0.269231  0.808989         0.071168        0.055202\n",
       "1   F-test  0.418064  0.307692  0.856180         0.071168        0.055202"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ber_tpr_tnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "    tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "    ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "    return ber, tpr, tnr\n",
    "\n",
    "\n",
    "class ReliefFSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, n_neighbors=10):\n",
    "        self.k = k\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        self.rf_ = ReliefF(n_features_to_select=self.k, n_neighbors=self.n_neighbors)\n",
    "        self.rf_.fit(X, y)\n",
    "        imp = np.asarray(self.rf_.feature_importances_, dtype=float)\n",
    "        imp = np.nan_to_num(imp, nan=-np.inf)\n",
    "        self.idx_ = np.argsort(imp)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "def build_pipe(method=\"relief\", k=40, n_neighbors=10, random_state=42):\n",
    "    if method == \"relief\":\n",
    "        selector = ReliefFSelector(k=k, n_neighbors=n_neighbors)\n",
    "    elif method == \"f\":\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'relief' or 'f'\")\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"sel\", selector),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "\n",
    "# ---------- Build chronological split ----------\n",
    "# Use aligned timestamp from L\n",
    "ts = pd.to_datetime(L[\"timestamp\"], errors=\"coerce\")\n",
    "valid = ts.notna().values\n",
    "\n",
    "Xv = X_base.loc[valid].copy()\n",
    "yv = y_bin[valid]\n",
    "tv = ts.loc[valid].reset_index(drop=True)\n",
    "\n",
    "order = np.argsort(tv.values)\n",
    "Xv = Xv.iloc[order].reset_index(drop=True)\n",
    "yv = yv[order]\n",
    "tv = tv.iloc[order].reset_index(drop=True)\n",
    "\n",
    "# Choose split point by time percentile (e.g., first 70% train, last 30% test)\n",
    "cut = int(0.70 * len(Xv))\n",
    "Xtr, Xte = Xv.iloc[:cut], Xv.iloc[cut:]\n",
    "ytr, yte = yv[:cut], yv[cut:]\n",
    "ttr, tte = tv.iloc[:cut], tv.iloc[cut:]\n",
    "\n",
    "print(\"Train range:\", ttr.min(), \"->\", ttr.max(), \"n=\", len(Xtr), \"fail_rate=\", ytr.mean())\n",
    "print(\"Test  range:\", tte.min(), \"->\", tte.max(), \"n=\", len(Xte), \"fail_rate=\", yte.mean())\n",
    "\n",
    "# ---------- Evaluate finalists ----------\n",
    "results = []\n",
    "for method in [\"relief\", \"f\"]:\n",
    "    pipe = build_pipe(method=method, k=40, n_neighbors=10, random_state=42)\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    pred = pipe.predict(Xte)\n",
    "    ber, tpr, tnr = ber_tpr_tnr(yte, pred)\n",
    "\n",
    "    results.append({\n",
    "        \"method\": \"ReliefF\" if method == \"relief\" else \"F-test\",\n",
    "        \"BER\": ber,\n",
    "        \"True+\": tpr,\n",
    "        \"True-\": tnr,\n",
    "        \"train_fail_rate\": float(ytr.mean()),\n",
    "        \"test_fail_rate\": float(yte.mean()),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9d754a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>method</th>\n",
       "      <th>BER</th>\n",
       "      <th>True+</th>\n",
       "      <th>True-</th>\n",
       "      <th>train_n</th>\n",
       "      <th>test_n</th>\n",
       "      <th>train_fail_rate</th>\n",
       "      <th>test_fail_rate</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60/40</td>\n",
       "      <td>F-test</td>\n",
       "      <td>0.501192</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.854758</td>\n",
       "      <td>940</td>\n",
       "      <td>627</td>\n",
       "      <td>0.080851</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-20 05:34:00</td>\n",
       "      <td>2008-09-20 06:08:00</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60/40</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.465657</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.782972</td>\n",
       "      <td>940</td>\n",
       "      <td>627</td>\n",
       "      <td>0.080851</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-20 05:34:00</td>\n",
       "      <td>2008-09-20 06:08:00</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70/30</td>\n",
       "      <td>F-test</td>\n",
       "      <td>0.418064</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.856180</td>\n",
       "      <td>1096</td>\n",
       "      <td>471</td>\n",
       "      <td>0.071168</td>\n",
       "      <td>0.055202</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-26 02:26:00</td>\n",
       "      <td>2008-09-26 03:12:00</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70/30</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.460890</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>1096</td>\n",
       "      <td>471</td>\n",
       "      <td>0.071168</td>\n",
       "      <td>0.055202</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-26 02:26:00</td>\n",
       "      <td>2008-09-26 03:12:00</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80/19</td>\n",
       "      <td>F-test</td>\n",
       "      <td>0.424540</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>1253</td>\n",
       "      <td>314</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>0.054140</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-10-02 19:25:00</td>\n",
       "      <td>2008-10-02 20:54:00</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80/19</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.355615</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1253</td>\n",
       "      <td>314</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>0.054140</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-10-02 19:25:00</td>\n",
       "      <td>2008-10-02 20:54:00</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cut   method       BER     True+     True-  train_n  test_n  \\\n",
       "0  60/40   F-test  0.501192  0.142857  0.854758      940     627   \n",
       "1  60/40  ReliefF  0.465657  0.285714  0.782972      940     627   \n",
       "2  70/30   F-test  0.418064  0.307692  0.856180     1096     471   \n",
       "3  70/30  ReliefF  0.460890  0.269231  0.808989     1096     471   \n",
       "4  80/19   F-test  0.424540  0.352941  0.797980     1253     314   \n",
       "5  80/19  ReliefF  0.355615  0.470588  0.818182     1253     314   \n",
       "\n",
       "   train_fail_rate  test_fail_rate         train_start           train_end  \\\n",
       "0         0.080851        0.044657 2008-07-19 11:55:00 2008-09-20 05:34:00   \n",
       "1         0.080851        0.044657 2008-07-19 11:55:00 2008-09-20 05:34:00   \n",
       "2         0.071168        0.055202 2008-07-19 11:55:00 2008-09-26 02:26:00   \n",
       "3         0.071168        0.055202 2008-07-19 11:55:00 2008-09-26 02:26:00   \n",
       "4         0.069433        0.054140 2008-07-19 11:55:00 2008-10-02 19:25:00   \n",
       "5         0.069433        0.054140 2008-07-19 11:55:00 2008-10-02 19:25:00   \n",
       "\n",
       "           test_start            test_end  \n",
       "0 2008-09-20 06:08:00 2008-10-17 06:07:00  \n",
       "1 2008-09-20 06:08:00 2008-10-17 06:07:00  \n",
       "2 2008-09-26 03:12:00 2008-10-17 06:07:00  \n",
       "3 2008-09-26 03:12:00 2008-10-17 06:07:00  \n",
       "4 2008-10-02 20:54:00 2008-10-17 06:07:00  \n",
       "5 2008-10-02 20:54:00 2008-10-17 06:07:00  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Prepare chronological dataset once\n",
    "ts = pd.to_datetime(L[\"timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "valid = ts.notna().values\n",
    "\n",
    "Xv = X_base.iloc[valid].copy()\n",
    "yv = y_bin[valid]\n",
    "tv = ts.iloc[valid].reset_index(drop=True)\n",
    "\n",
    "order = np.argsort(tv.values)\n",
    "Xv = Xv.iloc[order].reset_index(drop=True)\n",
    "yv = yv[order]\n",
    "tv = tv.iloc[order].reset_index(drop=True)\n",
    "\n",
    "# 2) Evaluate multiple train/test cut ratios\n",
    "cuts = [0.60, 0.70, 0.80]\n",
    "methods = [\"relief\", \"f\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for frac in cuts:\n",
    "    cut = int(frac * len(Xv))\n",
    "    Xtr, Xte = Xv.iloc[:cut], Xv.iloc[cut:]\n",
    "    ytr, yte = yv[:cut], yv[cut:]\n",
    "    ttr, tte = tv.iloc[:cut], tv.iloc[cut:]\n",
    "\n",
    "    for method in methods:\n",
    "        pipe = build_pipe(method=method, k=40, n_neighbors=10, random_state=42)\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        ber, tpr, tnr = ber_tpr_tnr(yte, pred)\n",
    "\n",
    "        rows.append({\n",
    "            \"cut\": f\"{int(frac*100)}/{int((1-frac)*100)}\",\n",
    "            \"method\": \"ReliefF\" if method == \"relief\" else \"F-test\",\n",
    "            \"BER\": ber,\n",
    "            \"True+\": tpr,\n",
    "            \"True-\": tnr,\n",
    "            \"train_n\": len(Xtr),\n",
    "            \"test_n\": len(Xte),\n",
    "            \"train_fail_rate\": float(ytr.mean()),\n",
    "            \"test_fail_rate\": float(yte.mean()),\n",
    "            \"train_start\": ttr.min(),\n",
    "            \"train_end\": ttr.max(),\n",
    "            \"test_start\": tte.min(),\n",
    "            \"test_end\": tte.max(),\n",
    "        })\n",
    "\n",
    "time_sens = pd.DataFrame(rows).sort_values([\"cut\", \"method\"]).reset_index(drop=True)\n",
    "time_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c415b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rolling splits: 8\n",
      "n=1567, min_train=783, test_size=235, step=78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_id</th>\n",
       "      <th>method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>train_BER_at_threshold</th>\n",
       "      <th>BER</th>\n",
       "      <th>True+</th>\n",
       "      <th>True-</th>\n",
       "      <th>train_n</th>\n",
       "      <th>test_n</th>\n",
       "      <th>train_fail_rate</th>\n",
       "      <th>test_fail_rate</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.211894</td>\n",
       "      <td>0.437316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.792035</td>\n",
       "      <td>783</td>\n",
       "      <td>235</td>\n",
       "      <td>0.085568</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-11 07:43:00</td>\n",
       "      <td>2008-09-11 08:06:00</td>\n",
       "      <td>2008-09-22 21:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F-test</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.213989</td>\n",
       "      <td>0.508358</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>783</td>\n",
       "      <td>235</td>\n",
       "      <td>0.085568</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-11 07:43:00</td>\n",
       "      <td>2008-09-11 08:06:00</td>\n",
       "      <td>2008-09-22 21:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.231895</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>861</td>\n",
       "      <td>235</td>\n",
       "      <td>0.082462</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-16 08:50:00</td>\n",
       "      <td>2008-09-16 08:52:00</td>\n",
       "      <td>2008-09-26 02:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>F-test</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.234899</td>\n",
       "      <td>0.471178</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>861</td>\n",
       "      <td>235</td>\n",
       "      <td>0.082462</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-16 08:50:00</td>\n",
       "      <td>2008-09-16 08:52:00</td>\n",
       "      <td>2008-09-26 02:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.556277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887446</td>\n",
       "      <td>939</td>\n",
       "      <td>235</td>\n",
       "      <td>0.080937</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-20 05:25:00</td>\n",
       "      <td>2008-09-20 05:34:00</td>\n",
       "      <td>2008-09-29 09:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split_id   method  threshold  train_BER_at_threshold       BER     True+  \\\n",
       "0         1  ReliefF      0.350                0.211894  0.437316  0.333333   \n",
       "1         1   F-test      0.350                0.213989  0.508358  0.222222   \n",
       "2         2  ReliefF      0.425                0.231895  0.549185  0.142857   \n",
       "3         2   F-test      0.375                0.234899  0.471178  0.285714   \n",
       "4         3  ReliefF      0.425                0.255900  0.556277  0.000000   \n",
       "\n",
       "      True-  train_n  test_n  train_fail_rate  test_fail_rate  \\\n",
       "0  0.792035      783     235         0.085568        0.038298   \n",
       "1  0.761062      783     235         0.085568        0.038298   \n",
       "2  0.758772      861     235         0.082462        0.029787   \n",
       "3  0.771930      861     235         0.082462        0.029787   \n",
       "4  0.887446      939     235         0.080937        0.017021   \n",
       "\n",
       "          train_start           train_end          test_start  \\\n",
       "0 2008-07-19 11:55:00 2008-09-11 07:43:00 2008-09-11 08:06:00   \n",
       "1 2008-07-19 11:55:00 2008-09-11 07:43:00 2008-09-11 08:06:00   \n",
       "2 2008-07-19 11:55:00 2008-09-16 08:50:00 2008-09-16 08:52:00   \n",
       "3 2008-07-19 11:55:00 2008-09-16 08:50:00 2008-09-16 08:52:00   \n",
       "4 2008-07-19 11:55:00 2008-09-20 05:25:00 2008-09-20 05:34:00   \n",
       "\n",
       "             test_end  \n",
       "0 2008-09-22 21:31:00  \n",
       "1 2008-09-22 21:31:00  \n",
       "2 2008-09-26 02:26:00  \n",
       "3 2008-09-26 02:26:00  \n",
       "4 2008-09-29 09:15:00  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assumes already defined:\n",
    "# - X_base, y_bin, L\n",
    "# - build_pipe(method=\"relief\"/\"f\", k=40, n_neighbors=10, random_state=42)\n",
    "# - ber_tpr_tnr(y_true, y_pred)\n",
    "\n",
    "# ---------- prepare chronological arrays ----------\n",
    "ts = pd.to_datetime(L[\"timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "valid = ts.notna().values\n",
    "\n",
    "Xv = X_base.iloc[valid].copy()\n",
    "yv = y_bin[valid]\n",
    "tv = ts.iloc[valid].reset_index(drop=True)\n",
    "\n",
    "order = np.argsort(tv.values)\n",
    "Xv = Xv.iloc[order].reset_index(drop=True)\n",
    "yv = yv[order]\n",
    "tv = tv.iloc[order].reset_index(drop=True)\n",
    "\n",
    "# ---------- helper: pick threshold on train only ----------\n",
    "def best_threshold_by_ber(y_true, p_true, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 37)\n",
    "    best_t, best_ber = 0.5, np.inf\n",
    "    for t in grid:\n",
    "        pred = (p_true >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, pred, labels=[0,1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)\n",
    "        tnr = tn / (tn + fp + 1e-12)\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "        if ber < best_ber:\n",
    "            best_ber = ber\n",
    "            best_t = float(t)\n",
    "    return best_t, best_ber\n",
    "\n",
    "# ---------- build rolling anchored splits ----------\n",
    "# Anchored train start at 0. For each split:\n",
    "# train = [0 : train_end), test = [train_end : train_end + test_size)\n",
    "n = len(Xv)\n",
    "test_frac = 0.15\n",
    "test_size = int(np.floor(test_frac * n))\n",
    "min_train_frac = 0.50\n",
    "min_train = int(np.floor(min_train_frac * n))\n",
    "step = max(30, test_size // 3)  # move window forward\n",
    "\n",
    "splits = []\n",
    "train_end = min_train\n",
    "while train_end + test_size <= n:\n",
    "    splits.append((0, train_end, train_end, train_end + test_size))\n",
    "    train_end += step\n",
    "\n",
    "print(f\"Total rolling splits: {len(splits)}\")\n",
    "print(f\"n={n}, min_train={min_train}, test_size={test_size}, step={step}\")\n",
    "\n",
    "# ---------- evaluate methods ----------\n",
    "rows = []\n",
    "for i, (tr_s, tr_e, te_s, te_e) in enumerate(splits, start=1):\n",
    "    Xtr, ytr = Xv.iloc[tr_s:tr_e], yv[tr_s:tr_e]\n",
    "    Xte, yte = Xv.iloc[te_s:te_e], yv[te_s:te_e]\n",
    "    ttr, tte = tv.iloc[tr_s:tr_e], tv.iloc[te_s:te_e]\n",
    "\n",
    "    # Skip pathological windows with no positive/negative\n",
    "    if len(np.unique(ytr)) < 2 or len(np.unique(yte)) < 2:\n",
    "        continue\n",
    "\n",
    "    for method in [\"relief\", \"f\"]:\n",
    "        pipe = build_pipe(method=method, k=40, n_neighbors=10, random_state=42)\n",
    "        pipe.fit(Xtr, ytr)\n",
    "\n",
    "        # threshold tuning on train probs only\n",
    "        p_tr = pipe.predict_proba(Xtr)[:, 1]\n",
    "        th, ber_tr = best_threshold_by_ber(ytr, p_tr)\n",
    "\n",
    "        # evaluate on test with tuned threshold\n",
    "        p_te = pipe.predict_proba(Xte)[:, 1]\n",
    "        pred_te = (p_te >= th).astype(int)\n",
    "        ber, tpr, tnr = ber_tpr_tnr(yte, pred_te)\n",
    "\n",
    "        rows.append({\n",
    "            \"split_id\": i,\n",
    "            \"method\": \"ReliefF\" if method == \"relief\" else \"F-test\",\n",
    "            \"threshold\": th,\n",
    "            \"train_BER_at_threshold\": ber_tr,\n",
    "            \"BER\": ber,\n",
    "            \"True+\": tpr,\n",
    "            \"True-\": tnr,\n",
    "            \"train_n\": len(Xtr),\n",
    "            \"test_n\": len(Xte),\n",
    "            \"train_fail_rate\": float(ytr.mean()),\n",
    "            \"test_fail_rate\": float(yte.mean()),\n",
    "            \"train_start\": ttr.min(),\n",
    "            \"train_end\": ttr.max(),\n",
    "            \"test_start\": tte.min(),\n",
    "            \"test_end\": tte.max(),\n",
    "        })\n",
    "\n",
    "rolling_df = pd.DataFrame(rows)\n",
    "rolling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e89678d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">BER</th>\n",
       "      <th colspan=\"3\" halign=\"left\">True+</th>\n",
       "      <th colspan=\"3\" halign=\"left\">True-</th>\n",
       "      <th colspan=\"3\" halign=\"left\">threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F-test</th>\n",
       "      <td>0.466426</td>\n",
       "      <td>0.088824</td>\n",
       "      <td>0.471902</td>\n",
       "      <td>0.314746</td>\n",
       "      <td>0.168216</td>\n",
       "      <td>0.332721</td>\n",
       "      <td>0.752403</td>\n",
       "      <td>0.075492</td>\n",
       "      <td>0.766496</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReliefF</th>\n",
       "      <td>0.465773</td>\n",
       "      <td>0.090120</td>\n",
       "      <td>0.476248</td>\n",
       "      <td>0.344570</td>\n",
       "      <td>0.257429</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.723885</td>\n",
       "      <td>0.194639</td>\n",
       "      <td>0.760120</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.075593</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BER                         True+                         True-  \\\n",
       "             mean       std    median      mean       std    median      mean   \n",
       "method                                                                          \n",
       "F-test   0.466426  0.088824  0.471902  0.314746  0.168216  0.332721  0.752403   \n",
       "ReliefF  0.465773  0.090120  0.476248  0.344570  0.257429  0.309524  0.723885   \n",
       "\n",
       "                            threshold                   \n",
       "              std    median      mean       std median  \n",
       "method                                                  \n",
       "F-test   0.075492  0.766496    0.4375  0.053452  0.450  \n",
       "ReliefF  0.194639  0.760120    0.4375  0.075593  0.425  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary table\n",
    "summary = (\n",
    "    rolling_df.groupby(\"method\")[[\"BER\", \"True+\", \"True-\", \"threshold\"]]\n",
    "    .agg([\"mean\", \"std\", \"median\"])\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78284ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>F-test</th>\n",
       "      <th>ReliefF</th>\n",
       "      <th>Relief_minus_F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.508358</td>\n",
       "      <td>0.437316</td>\n",
       "      <td>-0.071042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.471178</td>\n",
       "      <td>0.549185</td>\n",
       "      <td>0.078008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.556277</td>\n",
       "      <td>-0.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.472200</td>\n",
       "      <td>0.445820</td>\n",
       "      <td>-0.026380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.429034</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.101997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.508122</td>\n",
       "      <td>0.506676</td>\n",
       "      <td>-0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.471604</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>-0.059503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.287778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method      F-test   ReliefF  Relief_minus_F\n",
       "split_id                                    \n",
       "1         0.508358  0.437316       -0.071042\n",
       "2         0.471178  0.549185        0.078008\n",
       "3         0.590909  0.556277       -0.034632\n",
       "4         0.472200  0.445820       -0.026380\n",
       "5         0.429034  0.531031        0.101997\n",
       "6         0.508122  0.506676       -0.001446\n",
       "7         0.471604  0.412100       -0.059503\n",
       "8         0.280000  0.287778        0.007778"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: per-split comparison\n",
    "pivot_ber = rolling_df.pivot(index=\"split_id\", columns=\"method\", values=\"BER\")\n",
    "pivot_ber[\"Relief_minus_F\"] = pivot_ber[\"ReliefF\"] - pivot_ber[\"F-test\"]\n",
    "pivot_ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9b7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
