{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073b64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2adc629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: e:\\GitHub\\Mini-Projects\\secom-yield-monitoring\\notebooks\n",
      "X shape: (1567, 590)\n",
      "L shape: (1567, 2)\n",
      "Row counts match: True\n",
      "Feature count: 590\n",
      "Unique labels: [-1, 1]\n",
      "Label counts:\n",
      " y\n",
      "-1    1463\n",
      " 1     104\n",
      "Name: count, dtype: int64\n",
      "Timestamp parse success: 1.0\n",
      "Head labels+time:\n",
      "    y           timestamp\n",
      "0 -1 2008-07-19 11:55:00\n",
      "1 -1 2008-07-19 12:32:00\n",
      "2  1 2008-07-19 13:17:00\n",
      "3 -1 2008-07-19 14:43:00\n",
      "4 -1 2008-07-19 15:22:00\n"
     ]
    }
   ],
   "source": [
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"data\" / \"raw\" / \"secom.data\").exists():\n",
    "    ROOT = ROOT.parent  # handles running from notebooks/\n",
    "\n",
    "x_path = ROOT / \"data\" / \"raw\" / \"secom.data\"\n",
    "y_path = ROOT / \"data\" / \"raw\" / \"secom_labels.data\"\n",
    "\n",
    "X = pd.read_csv(x_path, sep=r\"\\s+\", header=None, na_values=[\"NaN\", \"nan\"])\n",
    "L = pd.read_csv(y_path, sep=r\"\\s+\", header=None)\n",
    "\n",
    "# Handle label/timestamp format variants\n",
    "if L.shape[1] == 3:\n",
    "    L.columns = [\"y\", \"date\", \"time\"]\n",
    "    L[\"timestamp\"] = pd.to_datetime(L[\"date\"] + \" \" + L[\"time\"], errors=\"coerce\")\n",
    "elif L.shape[1] == 2:\n",
    "    L.columns = [\"y\", \"timestamp\"]\n",
    "    L[\"timestamp\"] = pd.to_datetime(L[\"timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected label file shape: {L.shape}\")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"L shape:\", L.shape)\n",
    "print(\"Row counts match:\", len(X) == len(L))\n",
    "print(\"Feature count:\", X.shape[1])\n",
    "print(\"Unique labels:\", sorted(L[\"y\"].dropna().unique().tolist()))\n",
    "print(\"Label counts:\\n\", L[\"y\"].value_counts(dropna=False))\n",
    "print(\"Timestamp parse success:\", L[\"timestamp\"].notna().mean())\n",
    "print(\"Head labels+time:\\n\", L[[\"y\", \"timestamp\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecb1fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness summary:\n",
      "count    590.000000\n",
      "mean       0.045375\n",
      "std        0.154340\n",
      "min        0.000000\n",
      "25%        0.001276\n",
      "50%        0.003829\n",
      "75%        0.005743\n",
      "max        0.911934\n",
      "dtype: float64\n",
      "cols with >20% missing: 32\n",
      "cols with >40% missing: 32\n",
      "cols with >60% missing: 24\n",
      "cols with >80% missing: 8\n",
      "cols with >95% missing: 0\n",
      "\n",
      "Top 15 features where missingness differs by class:\n",
      "72     0.171960\n",
      "73     0.171960\n",
      "345    0.171960\n",
      "346    0.171960\n",
      "385    0.148858\n",
      "112    0.148858\n",
      "519    0.148858\n",
      "247    0.148858\n",
      "111    0.066289\n",
      "109    0.066289\n",
      "382    0.066289\n",
      "110    0.066289\n",
      "516    0.066289\n",
      "244    0.066289\n",
      "246    0.066289\n",
      "Name: delta_fail_minus_pass, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = (L[\"y\"] == 1).astype(int)  # 1=fail, 0=pass\n",
    "\n",
    "miss = X.isna().mean()\n",
    "print(\"Missingness summary:\")\n",
    "print(miss.describe())\n",
    "\n",
    "for t in [0.2, 0.4, 0.6, 0.8, 0.95]:\n",
    "    print(f\"cols with >{int(t*100)}% missing: {(miss > t).sum()}\")\n",
    "\n",
    "miss_by_class = pd.DataFrame({\n",
    "    \"pass_missing\": X[y == 0].isna().mean(),\n",
    "    \"fail_missing\": X[y == 1].isna().mean(),\n",
    "})\n",
    "miss_by_class[\"delta_fail_minus_pass\"] = miss_by_class[\"fail_missing\"] - miss_by_class[\"pass_missing\"]\n",
    "\n",
    "print(\"\\nTop 15 features where missingness differs by class:\")\n",
    "print(\n",
    "    miss_by_class[\"delta_fail_minus_pass\"]\n",
    "    .abs()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7186689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time range: 2008-07-19 11:55:00 -> 2008-10-17 06:07:00\n",
      "\n",
      "weekly fail-rate summary:\n",
      "count    14.000000\n",
      "mean      0.087106\n",
      "std       0.069633\n",
      "min       0.010638\n",
      "25%       0.034706\n",
      "50%       0.073364\n",
      "75%       0.123665\n",
      "max       0.230769\n",
      "Name: fail_rate, dtype: float64\n",
      "\n",
      "Top 10 highest-fail weeks:\n",
      "            count  fails  fail_rate\n",
      "timestamp                          \n",
      "2008-07-20     13      3   0.230769\n",
      "2008-08-03     48     10   0.208333\n",
      "2008-08-17     51      7   0.137255\n",
      "2008-08-10    108     14   0.129630\n",
      "2008-08-24    208     22   0.105769\n",
      "2008-07-27     21      2   0.095238\n",
      "2008-10-05    169     15   0.088757\n",
      "2008-10-12    138      8   0.057971\n",
      "2008-09-14     95      4   0.042105\n",
      "2008-08-31    169      7   0.041420\n",
      "\n",
      "Top 10 lowest-fail weeks:\n",
      "            count  fails  fail_rate\n",
      "timestamp                          \n",
      "2008-10-19     94      1   0.010638\n",
      "2008-09-07    133      2   0.015038\n",
      "2008-09-28    166      4   0.024096\n",
      "2008-09-21    154      5   0.032468\n",
      "2008-08-31    169      7   0.041420\n",
      "2008-09-14     95      4   0.042105\n",
      "2008-10-12    138      8   0.057971\n",
      "2008-10-05    169     15   0.088757\n",
      "2008-07-27     21      2   0.095238\n",
      "2008-08-24    208     22   0.105769\n"
     ]
    }
   ],
   "source": [
    "df = L.copy()\n",
    "df[\"fail\"] = (df[\"y\"] == 1).astype(int)\n",
    "df = df.sort_values(\"timestamp\")\n",
    "\n",
    "print(\"time range:\", df[\"timestamp\"].min(), \"->\", df[\"timestamp\"].max())\n",
    "\n",
    "weekly = (\n",
    "    df.set_index(\"timestamp\")[\"fail\"]\n",
    "      .resample(\"W\")\n",
    "      .agg([\"count\", \"sum\"])\n",
    "      .rename(columns={\"sum\": \"fails\"})\n",
    ") # type: ignore\n",
    "weekly[\"fail_rate\"] = weekly[\"fails\"] / weekly[\"count\"]\n",
    "\n",
    "print(\"\\nweekly fail-rate summary:\")\n",
    "print(weekly[\"fail_rate\"].describe())\n",
    "\n",
    "print(\"\\nTop 10 highest-fail weeks:\")\n",
    "print(weekly.sort_values(\"fail_rate\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop 10 lowest-fail weeks:\")\n",
    "print(weekly.sort_values(\"fail_rate\", ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a71eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant features: 116\n",
      "near-constant (>=99.5% same value): 122\n",
      "\n",
      "# pairs with |corr| >= 0.95: 316\n",
      "# pairs with |corr| >= 0.90: 397\n",
      "\n",
      "Top 20 absolute-correlation pairs:\n",
      "209  347    1.000000\n",
      "     342    1.000000\n",
      "     478    1.000000\n",
      "74   478    1.000000\n",
      "     209    1.000000\n",
      "     342    1.000000\n",
      "     347    1.000000\n",
      "342  347    1.000000\n",
      "347  478    1.000000\n",
      "206  209    1.000000\n",
      "     347    1.000000\n",
      "     478    1.000000\n",
      "74   206    1.000000\n",
      "206  342    1.000000\n",
      "342  478    1.000000\n",
      "34   36     1.000000\n",
      "140  275    1.000000\n",
      "172  174    1.000000\n",
      "307  309    0.999999\n",
      "152  287    0.999997\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# X already loaded\n",
    "n = len(X)\n",
    "\n",
    "# 1) Constant / near-constant\n",
    "nunique = X.nunique(dropna=True)\n",
    "const_cols = nunique[nunique <= 1].index.tolist()\n",
    "\n",
    "# near-constant by dominant value frequency (ignoring NaN)\n",
    "dom_frac = X.apply(lambda s: s.value_counts(dropna=True, normalize=True).iloc[0] if s.notna().any() else 1.0)\n",
    "near_const_cols = dom_frac[dom_frac >= 0.995].index.tolist()\n",
    "\n",
    "print(\"constant features:\", len(const_cols))\n",
    "print(\"near-constant (>=99.5% same value):\", len(near_const_cols))\n",
    "\n",
    "# 2) Correlation redundancy (after median impute only for this audit)\n",
    "Xi = X.copy()\n",
    "Xi = Xi.fillna(Xi.median(numeric_only=True))\n",
    "\n",
    "corr = Xi.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "high_corr_pairs = (upper.stack().sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n# pairs with |corr| >= 0.95:\", int((high_corr_pairs >= 0.95).sum()))\n",
    "print(\"# pairs with |corr| >= 0.90:\", int((high_corr_pairs >= 0.90).sum()))\n",
    "print(\"\\nTop 20 absolute-correlation pairs:\")\n",
    "print(high_corr_pairs.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bde467e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_const: 116\n",
      "drop_near_const: 122\n",
      "duplicate_components: 10\n",
      "drop_from_duplicates: 12\n",
      "final_keep_count: 456\n"
     ]
    }
   ],
   "source": [
    "y_bin = (L[\"y\"] == 1).astype(int)\n",
    "\n",
    "# base masks\n",
    "miss = X.isna().mean()\n",
    "dom = X.apply(lambda s: s.value_counts(dropna=True, normalize=True).iloc[0] if s.notna().any() else 1.0)\n",
    "nunique = X.nunique(dropna=True)\n",
    "\n",
    "drop_const = set(X.columns[nunique <= 1])\n",
    "drop_near_const = set(X.columns[dom >= 0.995])\n",
    "\n",
    "base_keep = [c for c in X.columns if c not in drop_const and c not in drop_near_const]\n",
    "Xi = X[base_keep].copy().fillna(X[base_keep].median())\n",
    "\n",
    "# high-corr duplicate graph\n",
    "corr = Xi.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "pairs = upper.stack()\n",
    "dup_pairs = pairs[pairs >= 0.9999].reset_index()\n",
    "dup_pairs.columns = [\"a\", \"b\", \"abs_corr\"]\n",
    "\n",
    "# adjacency\n",
    "adj = {c: set() for c in Xi.columns}\n",
    "for a, b, _ in dup_pairs.itertuples(index=False):\n",
    "    adj[a].add(b)\n",
    "    adj[b].add(a)\n",
    "\n",
    "# connected components\n",
    "seen, comps = set(), []\n",
    "for n in Xi.columns:\n",
    "    if n in seen or not adj[n]:\n",
    "        continue\n",
    "    stack, comp = [n], set()\n",
    "    while stack:\n",
    "        v = stack.pop()\n",
    "        if v in seen:\n",
    "            continue\n",
    "        seen.add(v)\n",
    "        comp.add(v)\n",
    "        stack.extend(adj[v] - seen)\n",
    "    comps.append(comp)\n",
    "\n",
    "# representative chooser\n",
    "var = Xi.var()\n",
    "yc = y_bin - y_bin.mean()\n",
    "rep_keep, rep_drop = set(), set()\n",
    "\n",
    "for comp in comps:\n",
    "    comp = list(comp)\n",
    "    # rank: lower missing, then higher variance, then higher |corr with y|\n",
    "    cxy = {}\n",
    "    for c in comp:\n",
    "        xc = Xi[c] - Xi[c].mean()\n",
    "        cxy[c] = abs((xc @ yc) / (np.linalg.norm(xc) * np.linalg.norm(yc) + 1e-12))\n",
    "    best = sorted(comp, key=lambda c: (miss[c], -var[c], -cxy[c]))[0]\n",
    "    rep_keep.add(best)\n",
    "    rep_drop.update(set(comp) - {best})\n",
    "\n",
    "final_drop = drop_const | drop_near_const | rep_drop\n",
    "final_keep = [c for c in X.columns if c not in final_drop]\n",
    "\n",
    "print(\"drop_const:\", len(drop_const))\n",
    "print(\"drop_near_const:\", len(drop_near_const))\n",
    "print(\"duplicate_components:\", len(comps))\n",
    "print(\"drop_from_duplicates:\", len(rep_drop))\n",
    "print(\"final_keep_count:\", len(final_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0de395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, r_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42139322",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = X[final_keep].copy()\n",
    "y_bin = (L[\"y\"] == 1).astype(int).values  # 1=fail, 0=pass\n",
    "\n",
    "def eval_baseline(add_indicator=True):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=add_indicator)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=42,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    rows = []\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)   # True+\n",
    "        tnr = tn / (tn + fp + 1e-12)   # True-\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(f\"\\nadd_indicator={add_indicator}\")\n",
    "    print(out[[\"BER\",\"True+\",\"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\",\"True+\",\"True-\"]].std().rename(\"std\"))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f80d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2NSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, eps=1e-12):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        pos = X[y == 1]\n",
    "        neg = X[y == 0]\n",
    "\n",
    "        mu_pos = np.nanmean(pos, axis=0)\n",
    "        mu_neg = np.nanmean(neg, axis=0)\n",
    "        sd_pos = np.nanstd(pos, axis=0, ddof=0)\n",
    "        sd_neg = np.nanstd(neg, axis=0, ddof=0)\n",
    "\n",
    "        scores = np.abs(mu_pos - mu_neg) / (sd_pos + sd_neg + self.eps)\n",
    "        scores = np.nan_to_num(scores, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        self.scores_ = scores\n",
    "        self.idx_ = np.argsort(scores)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "def run_s2n(k=40):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"s2n\", S2NSelector(k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=42,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0,1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)\n",
    "        tnr = tn / (tn + fp + 1e-12)\n",
    "        ber = 1 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"s2n\"].idx_\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\",\"True+\",\"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\",\"True+\",\"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1824289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WelchTSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, eps=1e-12):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        pos = X[y == 1]\n",
    "        neg = X[y == 0]\n",
    "\n",
    "        m1 = np.mean(pos, axis=0)\n",
    "        m0 = np.mean(neg, axis=0)\n",
    "        v1 = np.var(pos, axis=0, ddof=1)\n",
    "        v0 = np.var(neg, axis=0, ddof=1)\n",
    "        n1 = max(pos.shape[0], 1)\n",
    "        n0 = max(neg.shape[0], 1)\n",
    "\n",
    "        t = np.abs(m1 - m0) / (np.sqrt(v1 / n1 + v0 / n0) + self.eps)\n",
    "        t = np.nan_to_num(t, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        self.scores_ = t\n",
    "        self.idx_ = np.argsort(t)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "def run_t(k=40, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"tsel\", WelchTSelector(k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "        tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"tsel\"].idx_\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "\n",
    "    return out, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a6e6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_f(k=40, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"fsel\", SelectKBest(score_func=f_classif, k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    rows, selected_counts = [], {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)\n",
    "        tnr = tn / (tn + fp + 1e-12)\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"fsel\"].get_support(indices=True)\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b8ed4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pearson(k=40, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"psel\", SelectKBest(score_func=lambda X, y: np.abs(r_regression(X, y)), k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    rows, selected_counts = [], {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)\n",
    "        tnr = tn / (tn + fp + 1e-12)\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"psel\"].get_support(indices=True)\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcbe3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrebate import ReliefF\n",
    "\n",
    "class ReliefFSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, n_neighbors=10):\n",
    "        self.k = k\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        self.rf_ = ReliefF(\n",
    "            n_features_to_select=self.k,\n",
    "            n_neighbors=self.n_neighbors,\n",
    "        )\n",
    "        self.rf_.fit(X, y)\n",
    "\n",
    "        imp = np.asarray(self.rf_.feature_importances_, dtype=float)\n",
    "        imp = np.nan_to_num(imp, nan=-np.inf)\n",
    "        self.scores_ = imp\n",
    "        self.idx_ = np.argsort(imp)[::-1][: self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "def run_relieff(k=40, n_neighbors=10, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"rsel\", ReliefFSelector(k=k, n_neighbors=n_neighbors)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "        tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"rsel\"].idx_\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "\n",
    "    return out, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "514e9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramSchmidtSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=40, eps=1e-12):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "\n",
    "        n, p = X.shape\n",
    "        k = min(self.k, p)\n",
    "\n",
    "        # Work copies\n",
    "        Xw = X.copy()\n",
    "        r = y - y.mean()  # residual target direction\n",
    "\n",
    "        remaining = list(range(p))\n",
    "        selected = []\n",
    "        scores = []\n",
    "\n",
    "        for _ in range(k):\n",
    "            r_norm = np.linalg.norm(r)\n",
    "            if r_norm < self.eps or not remaining:\n",
    "                break\n",
    "\n",
    "            # score remaining features by absolute cosine with residual\n",
    "            best_j = None\n",
    "            best_score = -np.inf\n",
    "\n",
    "            for j in remaining:\n",
    "                xj = Xw[:, j]\n",
    "                x_norm = np.linalg.norm(xj)\n",
    "                if x_norm < self.eps:\n",
    "                    s = -np.inf\n",
    "                else:\n",
    "                    s = abs(np.dot(xj, r)) / (x_norm * r_norm + self.eps)\n",
    "\n",
    "                if s > best_score:\n",
    "                    best_score = s\n",
    "                    best_j = j\n",
    "\n",
    "            if best_j is None or not np.isfinite(best_score):\n",
    "                break\n",
    "\n",
    "            selected.append(best_j)\n",
    "            scores.append(best_score)\n",
    "\n",
    "            # orthonormal direction q of selected feature\n",
    "            q = Xw[:, best_j]\n",
    "            q_norm = np.linalg.norm(q)\n",
    "            if q_norm < self.eps:\n",
    "                remaining.remove(best_j)\n",
    "                continue\n",
    "            q = q / q_norm\n",
    "\n",
    "            # remove selected direction from residual and remaining features\n",
    "            r = r - np.dot(r, q) * q\n",
    "\n",
    "            for j in remaining:\n",
    "                if j == best_j:\n",
    "                    continue\n",
    "                Xw[:, j] = Xw[:, j] - np.dot(Xw[:, j], q) * q\n",
    "\n",
    "            remaining.remove(best_j)\n",
    "\n",
    "        self.idx_ = np.array(selected, dtype=int)\n",
    "        self.scores_ = np.array(scores, dtype=float)\n",
    "\n",
    "        # pad if early stop (rare)\n",
    "        if len(self.idx_) < k:\n",
    "            leftovers = [j for j in range(p) if j not in set(self.idx_)]\n",
    "            need = k - len(self.idx_)\n",
    "            self.idx_ = np.concatenate([self.idx_, np.array(leftovers[:need], dtype=int)])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "\n",
    "def run_gram_schmidt(k=40, random_state=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"gsel\", GramSchmidtSelector(k=k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        pred = pipe.predict(Xte)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "        tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "        ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        idx = pipe.named_steps[\"gsel\"].idx_\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "\n",
    "    return out, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94e95cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _metrics_from_pred(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "    tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "    ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "    return ber, tpr, tnr\n",
    "\n",
    "\n",
    "def run_l1(k=40, C=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Embedded selection via L1 logistic.\n",
    "    Top-k selected each fold by |coef| (on preprocessed train fold).\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"saga\",\n",
    "            C=C,\n",
    "            l1_ratio=1.0,  # new sklearn style for pure L1\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=8000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "\n",
    "        # rank by absolute coefficient, keep top-k\n",
    "        coef = np.abs(pipe.named_steps[\"clf\"].coef_[0])\n",
    "        idx = np.argsort(coef)[::-1][:k]\n",
    "\n",
    "        # transform train/test through preprocessors only, then subset columns\n",
    "        Xtr_t = pipe[:-1].transform(Xtr)[:, idx]\n",
    "        Xte_t = pipe[:-1].transform(Xte)[:, idx]\n",
    "\n",
    "        # refit logistic on selected columns only\n",
    "        clf2 = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=4000,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        clf2.fit(Xtr_t, ytr)\n",
    "        pred = clf2.predict(Xte_t)\n",
    "\n",
    "        ber, tpr, tnr = _metrics_from_pred(yte, pred)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(f\"L1 (C={C}, k={k})\")\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq\n",
    "\n",
    "\n",
    "def run_elasticnet(k=40, C=0.15, l1_ratio=0.4, random_state=42):\n",
    "    \"\"\"\n",
    "    Embedded selection via Elastic Net logistic.\n",
    "    Top-k selected each fold by |coef| (on preprocessed train fold).\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"saga\",\n",
    "            C=C,\n",
    "            l1_ratio=l1_ratio,\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=8000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    selected_counts = {}\n",
    "\n",
    "    for fold, (tr, te) in enumerate(cv.split(X_base, y_bin), start=1):\n",
    "        Xtr, Xte = X_base.iloc[tr], X_base.iloc[te]\n",
    "        ytr, yte = y_bin[tr], y_bin[te]\n",
    "\n",
    "        pipe.fit(Xtr, ytr)\n",
    "\n",
    "        # rank by absolute coefficient, keep top-k\n",
    "        coef = np.abs(pipe.named_steps[\"clf\"].coef_[0])\n",
    "        idx = np.argsort(coef)[::-1][:k]\n",
    "\n",
    "        # transform train/test through preprocessors only, then subset columns\n",
    "        Xtr_t = pipe[:-1].transform(Xtr)[:, idx]\n",
    "        Xte_t = pipe[:-1].transform(Xte)[:, idx]\n",
    "\n",
    "        # refit logistic on selected columns only\n",
    "        clf2 = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=4000,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        clf2.fit(Xtr_t, ytr)\n",
    "        pred = clf2.predict(Xte_t)\n",
    "\n",
    "        ber, tpr, tnr = _metrics_from_pred(yte, pred)\n",
    "        rows.append({\"fold\": fold, \"BER\": ber, \"True+\": tpr, \"True-\": tnr})\n",
    "\n",
    "        for j in idx:\n",
    "            selected_counts[j] = selected_counts.get(j, 0) + 1\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    print(f\"Elastic Net (C={C}, l1_ratio={l1_ratio}, k={k})\")\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].mean().rename(\"mean\"))\n",
    "    print(out[[\"BER\", \"True+\", \"True-\"]].std().rename(\"std\"))\n",
    "\n",
    "    freq = pd.Series(selected_counts).sort_values(ascending=False) / 10.0\n",
    "    print(\"\\nTop selected transformed columns (frequency across folds):\")\n",
    "    print(freq.head(20))\n",
    "    return out, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea9b7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_id</th>\n",
       "      <th>method</th>\n",
       "      <th>best_k</th>\n",
       "      <th>inner_BER</th>\n",
       "      <th>outer_BER</th>\n",
       "      <th>outer_True+</th>\n",
       "      <th>outer_True-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S2N</td>\n",
       "      <td>20</td>\n",
       "      <td>0.324261</td>\n",
       "      <td>0.537611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>60</td>\n",
       "      <td>0.412291</td>\n",
       "      <td>0.441740</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.783186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.291447</td>\n",
       "      <td>0.519912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>80</td>\n",
       "      <td>0.252505</td>\n",
       "      <td>0.477384</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.823009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Gram-Schmidt</td>\n",
       "      <td>20</td>\n",
       "      <td>0.226113</td>\n",
       "      <td>0.555310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.889381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>S2N</td>\n",
       "      <td>40</td>\n",
       "      <td>0.361561</td>\n",
       "      <td>0.603070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>60</td>\n",
       "      <td>0.472557</td>\n",
       "      <td>0.518484</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.820175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>F-test</td>\n",
       "      <td>80</td>\n",
       "      <td>0.365577</td>\n",
       "      <td>0.498747</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>80</td>\n",
       "      <td>0.304315</td>\n",
       "      <td>0.633772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.732456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Gram-Schmidt</td>\n",
       "      <td>60</td>\n",
       "      <td>0.419220</td>\n",
       "      <td>0.520677</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>S2N</td>\n",
       "      <td>10</td>\n",
       "      <td>0.444517</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>40</td>\n",
       "      <td>0.424984</td>\n",
       "      <td>0.599567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>F-test</td>\n",
       "      <td>80</td>\n",
       "      <td>0.480448</td>\n",
       "      <td>0.638528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.722944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>80</td>\n",
       "      <td>0.321330</td>\n",
       "      <td>0.632035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.735931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>Gram-Schmidt</td>\n",
       "      <td>20</td>\n",
       "      <td>0.479433</td>\n",
       "      <td>0.433442</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.883117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>S2N</td>\n",
       "      <td>20</td>\n",
       "      <td>0.511455</td>\n",
       "      <td>0.467938</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.973214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>10</td>\n",
       "      <td>0.511818</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>F-test</td>\n",
       "      <td>60</td>\n",
       "      <td>0.431532</td>\n",
       "      <td>0.414976</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.897321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>60</td>\n",
       "      <td>0.364066</td>\n",
       "      <td>0.517654</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.691964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>Gram-Schmidt</td>\n",
       "      <td>40</td>\n",
       "      <td>0.449376</td>\n",
       "      <td>0.569196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.861607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split_id        method  best_k  inner_BER  outer_BER  outer_True+  \\\n",
       "0          1           S2N      20   0.324261   0.537611     0.000000   \n",
       "1          1       Welch-t      60   0.412291   0.441740     0.333333   \n",
       "2          1        F-test      20   0.291447   0.519912     0.000000   \n",
       "3          1       ReliefF      80   0.252505   0.477384     0.222222   \n",
       "4          1  Gram-Schmidt      20   0.226113   0.555310     0.000000   \n",
       "5          2           S2N      40   0.361561   0.603070     0.000000   \n",
       "6          2       Welch-t      60   0.472557   0.518484     0.142857   \n",
       "7          2        F-test      80   0.365577   0.498747     0.142857   \n",
       "8          2       ReliefF      80   0.304315   0.633772     0.000000   \n",
       "9          2  Gram-Schmidt      60   0.419220   0.520677     0.142857   \n",
       "10         3           S2N      10   0.444517   0.506494     0.000000   \n",
       "11         3       Welch-t      40   0.424984   0.599567     0.000000   \n",
       "12         3        F-test      80   0.480448   0.638528     0.000000   \n",
       "13         3       ReliefF      80   0.321330   0.632035     0.000000   \n",
       "14         3  Gram-Schmidt      20   0.479433   0.433442     0.250000   \n",
       "15         4           S2N      20   0.511455   0.467938     0.090909   \n",
       "16         4       Welch-t      10   0.511818   0.504464     0.000000   \n",
       "17         4        F-test      60   0.431532   0.414976     0.272727   \n",
       "18         4       ReliefF      60   0.364066   0.517654     0.272727   \n",
       "19         4  Gram-Schmidt      40   0.449376   0.569196     0.000000   \n",
       "\n",
       "    outer_True-  \n",
       "0      0.924779  \n",
       "1      0.783186  \n",
       "2      0.960177  \n",
       "3      0.823009  \n",
       "4      0.889381  \n",
       "5      0.793860  \n",
       "6      0.820175  \n",
       "7      0.859649  \n",
       "8      0.732456  \n",
       "9      0.815789  \n",
       "10     0.987013  \n",
       "11     0.800866  \n",
       "12     0.722944  \n",
       "13     0.735931  \n",
       "14     0.883117  \n",
       "15     0.973214  \n",
       "16     0.991071  \n",
       "17     0.897321  \n",
       "18     0.691964  \n",
       "19     0.861607  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">outer_BER</th>\n",
       "      <th colspan=\"3\" halign=\"left\">outer_True+</th>\n",
       "      <th colspan=\"3\" halign=\"left\">outer_True-</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F-test</th>\n",
       "      <td>0.458857</td>\n",
       "      <td>0.102047</td>\n",
       "      <td>0.446175</td>\n",
       "      <td>0.235229</td>\n",
       "      <td>0.198248</td>\n",
       "      <td>0.242647</td>\n",
       "      <td>0.847057</td>\n",
       "      <td>0.073851</td>\n",
       "      <td>0.859048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gram-Schmidt</th>\n",
       "      <td>0.495218</td>\n",
       "      <td>0.078454</td>\n",
       "      <td>0.516903</td>\n",
       "      <td>0.134449</td>\n",
       "      <td>0.142689</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.875115</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>0.880811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReliefF</th>\n",
       "      <td>0.512753</td>\n",
       "      <td>0.094685</td>\n",
       "      <td>0.509938</td>\n",
       "      <td>0.205951</td>\n",
       "      <td>0.204358</td>\n",
       "      <td>0.199346</td>\n",
       "      <td>0.768542</td>\n",
       "      <td>0.102727</td>\n",
       "      <td>0.734193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2N</th>\n",
       "      <td>0.488631</td>\n",
       "      <td>0.058613</td>\n",
       "      <td>0.471697</td>\n",
       "      <td>0.156549</td>\n",
       "      <td>0.167683</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.866188</td>\n",
       "      <td>0.105346</td>\n",
       "      <td>0.889327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welch-t</th>\n",
       "      <td>0.478145</td>\n",
       "      <td>0.059148</td>\n",
       "      <td>0.447114</td>\n",
       "      <td>0.179499</td>\n",
       "      <td>0.130117</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.864211</td>\n",
       "      <td>0.073677</td>\n",
       "      <td>0.837028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             outer_BER                     outer_True+                      \\\n",
       "                  mean       std    median        mean       std    median   \n",
       "method                                                                       \n",
       "F-test        0.458857  0.102047  0.446175    0.235229  0.198248  0.242647   \n",
       "Gram-Schmidt  0.495218  0.078454  0.516903    0.134449  0.142689  0.119048   \n",
       "ReliefF       0.512753  0.094685  0.509938    0.205951  0.204358  0.199346   \n",
       "S2N           0.488631  0.058613  0.471697    0.156549  0.167683  0.145455   \n",
       "Welch-t       0.478145  0.059148  0.447114    0.179499  0.130117  0.188235   \n",
       "\n",
       "             outer_True-                      \n",
       "                    mean       std    median  \n",
       "method                                        \n",
       "F-test          0.847057  0.073851  0.859048  \n",
       "Gram-Schmidt    0.875115  0.051631  0.880811  \n",
       "ReliefF         0.768542  0.102727  0.734193  \n",
       "S2N             0.866188  0.105346  0.889327  \n",
       "Welch-t         0.864211  0.073677  0.837028  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>best_k</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>40</th>\n",
       "      <th>60</th>\n",
       "      <th>80</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F-test</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gram-Schmidt</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReliefF</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2N</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welch-t</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "best_k        10  20  40  60  80\n",
       "method                          \n",
       "F-test         1   3   1   1   2\n",
       "Gram-Schmidt   0   4   1   2   1\n",
       "ReliefF        1   0   1   1   5\n",
       "S2N            1   2   2   1   2\n",
       "Welch-t        2   0   1   3   2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DropAllNaNCols(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        self.keep_idx_ = np.where(~np.all(np.isnan(X), axis=0))[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return X[:, self.keep_idx_]\n",
    "\n",
    "def ber_tpr_tnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    tpr = tp / (tp + fn + 1e-12)\n",
    "    tnr = tn / (tn + fp + 1e-12)\n",
    "    ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "    return ber, tpr, tnr\n",
    "\n",
    "def anchored_splits(n, min_train, test_size, step):\n",
    "    out = []\n",
    "    tr_end = min_train\n",
    "    while tr_end + test_size <= n:\n",
    "        out.append((0, tr_end, tr_end, tr_end + test_size))\n",
    "        tr_end += step\n",
    "    return out\n",
    "\n",
    "def build_selector(method, k):\n",
    "    if method == \"S2N\":\n",
    "        return S2NSelector(k=k)\n",
    "    if method == \"Welch-t\":\n",
    "        return WelchTSelector(k=k)\n",
    "    if method == \"F-test\":\n",
    "        return SelectKBest(score_func=f_classif, k=k)\n",
    "    if method == \"Pearson\":\n",
    "        # optional: skip because usually same as F-test in this binary setup\n",
    "        return SelectKBest(score_func=f_classif, k=k)\n",
    "    if method == \"ReliefF\":\n",
    "        return ReliefFSelector(k=k, n_neighbors=10)\n",
    "    if method == \"Gram-Schmidt\":\n",
    "        return GramSchmidtSelector(k=k)\n",
    "    raise ValueError(method)\n",
    "\n",
    "def eval_once(Xtr, ytr, Xte, yte, method, k, seed=42):\n",
    "    pipe = Pipeline([\n",
    "        (\"drop_all_nan\", DropAllNaNCols()),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"sel\", build_selector(method, k)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=seed\n",
    "        )),\n",
    "    ])\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    pred = pipe.predict(Xte)\n",
    "    return ber_tpr_tnr(yte, pred)\n",
    "\n",
    "# --- chronological order ---\n",
    "ts = pd.to_datetime(L[\"timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "valid = ts.notna().values\n",
    "\n",
    "Xv = X_base.iloc[valid].copy()\n",
    "yv = y_bin[valid]\n",
    "tv = ts.iloc[valid].reset_index(drop=True)\n",
    "\n",
    "order = np.argsort(tv.values)\n",
    "Xv = Xv.iloc[order].reset_index(drop=True)\n",
    "yv = yv[order]\n",
    "\n",
    "# --- config ---\n",
    "methods = [\"S2N\", \"Welch-t\", \"F-test\", \"ReliefF\", \"Gram-Schmidt\"]  # add/remove as needed\n",
    "k_grid = [10, 20, 40, 60, 80]\n",
    "outer = anchored_splits(\n",
    "    n=len(Xv),\n",
    "    min_train=int(0.50 * len(Xv)),\n",
    "    test_size=int(0.15 * len(Xv)),\n",
    "    step=max(30, int(0.15 * len(Xv)) // 3),\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for split_id, (tr_s, tr_e, te_s, te_e) in enumerate(outer, start=1):\n",
    "    Xtr_outer, ytr_outer = Xv.iloc[tr_s:tr_e], yv[tr_s:tr_e]\n",
    "    Xte_outer, yte_outer = Xv.iloc[te_s:te_e], yv[te_s:te_e]\n",
    "\n",
    "    # inner time-aware splits inside outer-train\n",
    "    n_in = len(Xtr_outer)\n",
    "    inner = anchored_splits(\n",
    "        n=n_in,\n",
    "        min_train=max(200, int(0.60 * n_in)),\n",
    "        test_size=max(60, int(0.20 * n_in)),\n",
    "        step=max(20, int(0.20 * n_in) // 2),\n",
    "    )\n",
    "\n",
    "    for method in methods:\n",
    "        k_to_inner_ber = {}\n",
    "\n",
    "        for k in k_grid:\n",
    "            inner_bers = []\n",
    "            for (i_tr_s, i_tr_e, i_va_s, i_va_e) in inner:\n",
    "                Xi_tr = Xtr_outer.iloc[i_tr_s:i_tr_e]\n",
    "                yi_tr = ytr_outer[i_tr_s:i_tr_e]\n",
    "                Xi_va = Xtr_outer.iloc[i_va_s:i_va_e]\n",
    "                yi_va = ytr_outer[i_va_s:i_va_e]\n",
    "\n",
    "                if len(np.unique(yi_tr)) < 2 or len(np.unique(yi_va)) < 2:\n",
    "                    continue\n",
    "\n",
    "                ber, _, _ = eval_once(Xi_tr, yi_tr, Xi_va, yi_va, method, k)\n",
    "                inner_bers.append(ber)\n",
    "\n",
    "            if inner_bers:\n",
    "                k_to_inner_ber[k] = float(np.mean(inner_bers))\n",
    "\n",
    "        if not k_to_inner_ber:\n",
    "            continue\n",
    "\n",
    "        best_k = min(k_to_inner_ber, key=k_to_inner_ber.get)\n",
    "        ber, tpr, tnr = eval_once(Xtr_outer, ytr_outer, Xte_outer, yte_outer, method, best_k)\n",
    "\n",
    "        rows.append({\n",
    "            \"split_id\": split_id,\n",
    "            \"method\": method,\n",
    "            \"best_k\": best_k,\n",
    "            \"inner_BER\": k_to_inner_ber[best_k],\n",
    "            \"outer_BER\": ber,\n",
    "            \"outer_True+\": tpr,\n",
    "            \"outer_True-\": tnr,\n",
    "        })\n",
    "\n",
    "res = pd.DataFrame(rows)\n",
    "display(res.head(20))\n",
    "\n",
    "summary = (\n",
    "    res.groupby(\"method\")[[\"outer_BER\", \"outer_True+\", \"outer_True-\"]]\n",
    "    .agg([\"mean\", \"std\", \"median\"])\n",
    ")\n",
    "display(summary)\n",
    "\n",
    "k_usage = res.groupby([\"method\", \"best_k\"]).size().unstack(fill_value=0)\n",
    "display(k_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db69e4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_id</th>\n",
       "      <th>method</th>\n",
       "      <th>k</th>\n",
       "      <th>threshold</th>\n",
       "      <th>train_BER_at_threshold</th>\n",
       "      <th>outer_BER</th>\n",
       "      <th>outer_True+</th>\n",
       "      <th>outer_True-</th>\n",
       "      <th>train_n</th>\n",
       "      <th>test_n</th>\n",
       "      <th>train_fail_rate</th>\n",
       "      <th>test_fail_rate</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.181126</td>\n",
       "      <td>0.481563</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.703540</td>\n",
       "      <td>783</td>\n",
       "      <td>235</td>\n",
       "      <td>0.085568</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-11 07:43:00</td>\n",
       "      <td>2008-09-11 08:06:00</td>\n",
       "      <td>2008-09-22 21:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.176582</td>\n",
       "      <td>0.437316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.792035</td>\n",
       "      <td>783</td>\n",
       "      <td>235</td>\n",
       "      <td>0.085568</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-11 07:43:00</td>\n",
       "      <td>2008-09-11 08:06:00</td>\n",
       "      <td>2008-09-22 21:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.189089</td>\n",
       "      <td>0.571115</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.714912</td>\n",
       "      <td>861</td>\n",
       "      <td>235</td>\n",
       "      <td>0.082462</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-16 08:50:00</td>\n",
       "      <td>2008-09-16 08:52:00</td>\n",
       "      <td>2008-09-26 02:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.197798</td>\n",
       "      <td>0.522870</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>861</td>\n",
       "      <td>235</td>\n",
       "      <td>0.082462</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-16 08:50:00</td>\n",
       "      <td>2008-09-16 08:52:00</td>\n",
       "      <td>2008-09-26 02:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.200784</td>\n",
       "      <td>0.673160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>939</td>\n",
       "      <td>235</td>\n",
       "      <td>0.080937</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-20 05:25:00</td>\n",
       "      <td>2008-09-20 05:34:00</td>\n",
       "      <td>2008-09-29 09:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.222091</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>939</td>\n",
       "      <td>235</td>\n",
       "      <td>0.080937</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-20 05:25:00</td>\n",
       "      <td>2008-09-20 05:34:00</td>\n",
       "      <td>2008-09-29 09:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.195439</td>\n",
       "      <td>0.398539</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>1017</td>\n",
       "      <td>235</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.046809</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-22 21:30:00</td>\n",
       "      <td>2008-09-22 21:31:00</td>\n",
       "      <td>2008-10-02 19:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.198550</td>\n",
       "      <td>0.455966</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>1017</td>\n",
       "      <td>235</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.046809</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-22 21:30:00</td>\n",
       "      <td>2008-09-22 21:31:00</td>\n",
       "      <td>2008-10-02 19:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.204164</td>\n",
       "      <td>0.458446</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>1095</td>\n",
       "      <td>235</td>\n",
       "      <td>0.071233</td>\n",
       "      <td>0.072340</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-26 01:21:00</td>\n",
       "      <td>2008-09-26 02:26:00</td>\n",
       "      <td>2008-10-05 18:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.218478</td>\n",
       "      <td>0.425931</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.912844</td>\n",
       "      <td>1095</td>\n",
       "      <td>235</td>\n",
       "      <td>0.071233</td>\n",
       "      <td>0.072340</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-26 01:21:00</td>\n",
       "      <td>2008-09-26 02:26:00</td>\n",
       "      <td>2008-10-05 18:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.217875</td>\n",
       "      <td>0.447374</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>1173</td>\n",
       "      <td>235</td>\n",
       "      <td>0.068201</td>\n",
       "      <td>0.089362</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-29 07:53:00</td>\n",
       "      <td>2008-09-29 09:15:00</td>\n",
       "      <td>2008-10-07 19:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.213769</td>\n",
       "      <td>0.453939</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>1173</td>\n",
       "      <td>235</td>\n",
       "      <td>0.068201</td>\n",
       "      <td>0.089362</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-09-29 07:53:00</td>\n",
       "      <td>2008-09-29 09:15:00</td>\n",
       "      <td>2008-10-07 19:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.224153</td>\n",
       "      <td>0.499001</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.689498</td>\n",
       "      <td>1251</td>\n",
       "      <td>235</td>\n",
       "      <td>0.069544</td>\n",
       "      <td>0.068085</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-10-02 17:19:00</td>\n",
       "      <td>2008-10-02 19:21:00</td>\n",
       "      <td>2008-10-13 19:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.266071</td>\n",
       "      <td>0.454053</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.716895</td>\n",
       "      <td>1251</td>\n",
       "      <td>235</td>\n",
       "      <td>0.069544</td>\n",
       "      <td>0.068085</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-10-02 17:19:00</td>\n",
       "      <td>2008-10-02 19:21:00</td>\n",
       "      <td>2008-10-13 19:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.237893</td>\n",
       "      <td>0.235556</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.928889</td>\n",
       "      <td>1329</td>\n",
       "      <td>235</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-10-05 16:49:00</td>\n",
       "      <td>2008-10-05 18:46:00</td>\n",
       "      <td>2008-10-16 20:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.263998</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1329</td>\n",
       "      <td>235</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>2008-10-05 16:49:00</td>\n",
       "      <td>2008-10-05 18:46:00</td>\n",
       "      <td>2008-10-16 20:49:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split_id   method   k  threshold  train_BER_at_threshold  outer_BER  \\\n",
       "0          1   F-test  20       0.34                0.181126   0.481563   \n",
       "1          1  Welch-t  20       0.55                0.176582   0.437316   \n",
       "2          2   F-test  20       0.38                0.189089   0.571115   \n",
       "3          2  Welch-t  20       0.47                0.197798   0.522870   \n",
       "4          3   F-test  20       0.43                0.200784   0.673160   \n",
       "5          3  Welch-t  20       0.52                0.222091   0.597403   \n",
       "6          4   F-test  20       0.43                0.195439   0.398539   \n",
       "7          4  Welch-t  20       0.43                0.198550   0.455966   \n",
       "8          5   F-test  20       0.39                0.204164   0.458446   \n",
       "9          5  Welch-t  20       0.45                0.218478   0.425931   \n",
       "10         6   F-test  20       0.46                0.217875   0.447374   \n",
       "11         6  Welch-t  20       0.40                0.213769   0.453939   \n",
       "12         7   F-test  20       0.49                0.224153   0.499001   \n",
       "13         7  Welch-t  20       0.38                0.266071   0.454053   \n",
       "14         8   F-test  20       0.54                0.237893   0.235556   \n",
       "15         8  Welch-t  20       0.43                0.263998   0.405556   \n",
       "\n",
       "    outer_True+  outer_True-  train_n  test_n  train_fail_rate  \\\n",
       "0      0.333333     0.703540      783     235         0.085568   \n",
       "1      0.333333     0.792035      783     235         0.085568   \n",
       "2      0.142857     0.714912      861     235         0.082462   \n",
       "3      0.142857     0.811404      861     235         0.082462   \n",
       "4      0.000000     0.653680      939     235         0.080937   \n",
       "5      0.000000     0.805195      939     235         0.080937   \n",
       "6      0.363636     0.839286     1017     235         0.074730   \n",
       "7      0.181818     0.906250     1017     235         0.074730   \n",
       "8      0.294118     0.788991     1095     235         0.071233   \n",
       "9      0.235294     0.912844     1095     235         0.071233   \n",
       "10     0.380952     0.724299     1173     235         0.068201   \n",
       "11     0.428571     0.663551     1173     235         0.068201   \n",
       "12     0.312500     0.689498     1251     235         0.069544   \n",
       "13     0.375000     0.716895     1251     235         0.069544   \n",
       "14     0.600000     0.928889     1329     235         0.070730   \n",
       "15     0.300000     0.888889     1329     235         0.070730   \n",
       "\n",
       "    test_fail_rate         train_start           train_end  \\\n",
       "0         0.038298 2008-07-19 11:55:00 2008-09-11 07:43:00   \n",
       "1         0.038298 2008-07-19 11:55:00 2008-09-11 07:43:00   \n",
       "2         0.029787 2008-07-19 11:55:00 2008-09-16 08:50:00   \n",
       "3         0.029787 2008-07-19 11:55:00 2008-09-16 08:50:00   \n",
       "4         0.017021 2008-07-19 11:55:00 2008-09-20 05:25:00   \n",
       "5         0.017021 2008-07-19 11:55:00 2008-09-20 05:25:00   \n",
       "6         0.046809 2008-07-19 11:55:00 2008-09-22 21:30:00   \n",
       "7         0.046809 2008-07-19 11:55:00 2008-09-22 21:30:00   \n",
       "8         0.072340 2008-07-19 11:55:00 2008-09-26 01:21:00   \n",
       "9         0.072340 2008-07-19 11:55:00 2008-09-26 01:21:00   \n",
       "10        0.089362 2008-07-19 11:55:00 2008-09-29 07:53:00   \n",
       "11        0.089362 2008-07-19 11:55:00 2008-09-29 07:53:00   \n",
       "12        0.068085 2008-07-19 11:55:00 2008-10-02 17:19:00   \n",
       "13        0.068085 2008-07-19 11:55:00 2008-10-02 17:19:00   \n",
       "14        0.042553 2008-07-19 11:55:00 2008-10-05 16:49:00   \n",
       "15        0.042553 2008-07-19 11:55:00 2008-10-05 16:49:00   \n",
       "\n",
       "            test_start            test_end  \n",
       "0  2008-09-11 08:06:00 2008-09-22 21:31:00  \n",
       "1  2008-09-11 08:06:00 2008-09-22 21:31:00  \n",
       "2  2008-09-16 08:52:00 2008-09-26 02:26:00  \n",
       "3  2008-09-16 08:52:00 2008-09-26 02:26:00  \n",
       "4  2008-09-20 05:34:00 2008-09-29 09:15:00  \n",
       "5  2008-09-20 05:34:00 2008-09-29 09:15:00  \n",
       "6  2008-09-22 21:31:00 2008-10-02 19:21:00  \n",
       "7  2008-09-22 21:31:00 2008-10-02 19:21:00  \n",
       "8  2008-09-26 02:26:00 2008-10-05 18:46:00  \n",
       "9  2008-09-26 02:26:00 2008-10-05 18:46:00  \n",
       "10 2008-09-29 09:15:00 2008-10-07 19:24:00  \n",
       "11 2008-09-29 09:15:00 2008-10-07 19:24:00  \n",
       "12 2008-10-02 19:21:00 2008-10-13 19:36:00  \n",
       "13 2008-10-02 19:21:00 2008-10-13 19:36:00  \n",
       "14 2008-10-05 18:46:00 2008-10-16 20:49:00  \n",
       "15 2008-10-05 18:46:00 2008-10-16 20:49:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">outer_BER</th>\n",
       "      <th colspan=\"3\" halign=\"left\">outer_True+</th>\n",
       "      <th colspan=\"3\" halign=\"left\">outer_True-</th>\n",
       "      <th colspan=\"3\" halign=\"left\">threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F-test</th>\n",
       "      <td>0.470594</td>\n",
       "      <td>0.127159</td>\n",
       "      <td>0.470005</td>\n",
       "      <td>0.303425</td>\n",
       "      <td>0.175867</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.755387</td>\n",
       "      <td>0.091222</td>\n",
       "      <td>0.719606</td>\n",
       "      <td>0.43250</td>\n",
       "      <td>0.064087</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welch-t</th>\n",
       "      <td>0.469129</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.453996</td>\n",
       "      <td>0.249609</td>\n",
       "      <td>0.139284</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.812133</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.808299</td>\n",
       "      <td>0.45375</td>\n",
       "      <td>0.057802</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        outer_BER                     outer_True+                      \\\n",
       "             mean       std    median        mean       std    median   \n",
       "method                                                                  \n",
       "F-test   0.470594  0.127159  0.470005    0.303425  0.175867  0.322917   \n",
       "Welch-t  0.469129  0.061983  0.453996    0.249609  0.139284  0.267647   \n",
       "\n",
       "        outer_True-                     threshold                   \n",
       "               mean       std    median      mean       std median  \n",
       "method                                                              \n",
       "F-test     0.755387  0.091222  0.719606   0.43250  0.064087   0.43  \n",
       "Welch-t    0.812133  0.089834  0.808299   0.45375  0.057802   0.44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>F-test</th>\n",
       "      <th>Welch-t</th>\n",
       "      <th>Welch_minus_F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481563</td>\n",
       "      <td>0.437316</td>\n",
       "      <td>-0.044248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571115</td>\n",
       "      <td>0.522870</td>\n",
       "      <td>-0.048246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.673160</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>-0.075758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.398539</td>\n",
       "      <td>0.455966</td>\n",
       "      <td>0.057427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.458446</td>\n",
       "      <td>0.425931</td>\n",
       "      <td>-0.032515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.447374</td>\n",
       "      <td>0.453939</td>\n",
       "      <td>0.006564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.499001</td>\n",
       "      <td>0.454053</td>\n",
       "      <td>-0.044949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235556</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method      F-test   Welch-t  Welch_minus_F\n",
       "split_id                                   \n",
       "1         0.481563  0.437316      -0.044248\n",
       "2         0.571115  0.522870      -0.048246\n",
       "3         0.673160  0.597403      -0.075758\n",
       "4         0.398539  0.455966       0.057427\n",
       "5         0.458446  0.425931      -0.032515\n",
       "6         0.447374  0.453939       0.006564\n",
       "7         0.499001  0.454053      -0.044949\n",
       "8         0.235556  0.405556       0.170000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- utilities ----------\n",
    "def ber_tpr_tnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    tpr = tp / (tp + fn + 1e-12)  # True+\n",
    "    tnr = tn / (tn + fp + 1e-12)  # True-\n",
    "    ber = 1.0 - 0.5 * (tpr + tnr)\n",
    "    return ber, tpr, tnr\n",
    "\n",
    "def best_threshold_by_ber(y_true, p_true, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 91)\n",
    "    best_t, best_ber = 0.5, np.inf\n",
    "    for t in grid:\n",
    "        pred = (p_true >= t).astype(int)\n",
    "        ber, _, _ = ber_tpr_tnr(y_true, pred)\n",
    "        if ber < best_ber:\n",
    "            best_ber = ber\n",
    "            best_t = float(t)\n",
    "    return best_t, best_ber\n",
    "\n",
    "def anchored_splits(n, min_train, test_size, step):\n",
    "    out = []\n",
    "    tr_end = min_train\n",
    "    while tr_end + test_size <= n:\n",
    "        out.append((0, tr_end, tr_end, tr_end + test_size))\n",
    "        tr_end += step\n",
    "    return out\n",
    "\n",
    "class DropAllNaNCols(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        self.keep_idx_ = np.where(~np.all(np.isnan(X), axis=0))[0]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return X[:, self.keep_idx_]\n",
    "\n",
    "class WelchTSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=20, eps=1e-12):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        pos = X[y == 1]\n",
    "        neg = X[y == 0]\n",
    "        m1, m0 = np.mean(pos, axis=0), np.mean(neg, axis=0)\n",
    "        v1, v0 = np.var(pos, axis=0, ddof=1), np.var(neg, axis=0, ddof=1)\n",
    "        n1, n0 = max(len(pos), 1), max(len(neg), 1)\n",
    "        t = np.abs(m1 - m0) / (np.sqrt(v1 / n1 + v0 / n0) + self.eps)\n",
    "        t = np.nan_to_num(t, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        self.idx_ = np.argsort(t)[::-1][: self.k]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.asarray(X)[:, self.idx_]\n",
    "\n",
    "def build_pipe(method=\"F-test\", k=20, random_state=42):\n",
    "    if method == \"F-test\":\n",
    "        sel = SelectKBest(score_func=f_classif, k=k)\n",
    "    elif method == \"Welch-t\":\n",
    "        sel = WelchTSelector(k=k)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'F-test' or 'Welch-t'\")\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"drop_all_nan\", DropAllNaNCols()),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"sel\", sel),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "\n",
    "# ---------- chronological data ----------\n",
    "ts = pd.to_datetime(L[\"timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "valid = ts.notna().values\n",
    "\n",
    "Xv = X_base.iloc[valid].copy()\n",
    "yv = y_bin[valid]\n",
    "tv = ts.iloc[valid].reset_index(drop=True)\n",
    "\n",
    "order = np.argsort(tv.values)\n",
    "Xv = Xv.iloc[order].reset_index(drop=True)\n",
    "yv = yv[order]\n",
    "tv = tv.iloc[order].reset_index(drop=True)\n",
    "\n",
    "# ---------- split config ----------\n",
    "n = len(Xv)\n",
    "splits = anchored_splits(\n",
    "    n=n,\n",
    "    min_train=int(0.50 * n),\n",
    "    test_size=int(0.15 * n),\n",
    "    step=max(30, int(0.15 * n) // 3),\n",
    ")\n",
    "\n",
    "# ---------- run ----------\n",
    "rows = []\n",
    "for split_id, (tr_s, tr_e, te_s, te_e) in enumerate(splits, start=1):\n",
    "    Xtr, ytr = Xv.iloc[tr_s:tr_e], yv[tr_s:tr_e]\n",
    "    Xte, yte = Xv.iloc[te_s:te_e], yv[te_s:te_e]\n",
    "    ttr, tte = tv.iloc[tr_s:tr_e], tv.iloc[te_s:te_e]\n",
    "\n",
    "    # skip pathological windows\n",
    "    if len(np.unique(ytr)) < 2 or len(np.unique(yte)) < 2:\n",
    "        continue\n",
    "\n",
    "    for method in [\"F-test\", \"Welch-t\"]:\n",
    "        pipe = build_pipe(method=method, k=60, random_state=42)\n",
    "        pipe.fit(Xtr, ytr)\n",
    "\n",
    "        # threshold from train probabilities only\n",
    "        p_tr = pipe.predict_proba(Xtr)[:, 1]\n",
    "        th, tr_ber = best_threshold_by_ber(ytr, p_tr)\n",
    "\n",
    "        # evaluate on test at tuned threshold\n",
    "        p_te = pipe.predict_proba(Xte)[:, 1]\n",
    "        pred_te = (p_te >= th).astype(int)\n",
    "        ber, tpr, tnr = ber_tpr_tnr(yte, pred_te)\n",
    "\n",
    "        rows.append({\n",
    "            \"split_id\": split_id,\n",
    "            \"method\": method,\n",
    "            \"k\": 20,\n",
    "            \"threshold\": th,\n",
    "            \"train_BER_at_threshold\": tr_ber,\n",
    "            \"outer_BER\": ber,\n",
    "            \"outer_True+\": tpr,\n",
    "            \"outer_True-\": tnr,\n",
    "            \"train_n\": len(Xtr),\n",
    "            \"test_n\": len(Xte),\n",
    "            \"train_fail_rate\": float(ytr.mean()),\n",
    "            \"test_fail_rate\": float(yte.mean()),\n",
    "            \"train_start\": ttr.min(),\n",
    "            \"train_end\": ttr.max(),\n",
    "            \"test_start\": tte.min(),\n",
    "            \"test_end\": tte.max(),\n",
    "        })\n",
    "\n",
    "tuned_df = pd.DataFrame(rows)\n",
    "display(tuned_df)\n",
    "\n",
    "summary = (\n",
    "    tuned_df.groupby(\"method\")[[\"outer_BER\", \"outer_True+\", \"outer_True-\", \"threshold\"]]\n",
    "    .agg([\"mean\", \"std\", \"median\"])\n",
    ")\n",
    "display(summary)\n",
    "\n",
    "pivot = tuned_df.pivot(index=\"split_id\", columns=\"method\", values=\"outer_BER\")\n",
    "pivot[\"Welch_minus_F\"] = pivot[\"Welch-t\"] - pivot[\"F-test\"]\n",
    "display(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "439e2019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV  : 1331 fail_rate= 0.07137490608564989 2008-07-19 11:55:00 -> 2008-10-05 18:59:00\n",
      "LOCK : 236 fail_rate= 0.038135593220338986 2008-10-05 19:45:00 -> 2008-10-17 06:07:00\n"
     ]
    }
   ],
   "source": [
    "# assumes X_base, y_bin, L exist and align\n",
    "ts = pd.to_datetime(L[\"timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "valid = ts.notna().values\n",
    "\n",
    "Xv = X_base.iloc[valid].copy()\n",
    "yv = y_bin[valid]\n",
    "tv = ts.iloc[valid].reset_index(drop=True)\n",
    "\n",
    "order = np.argsort(tv.values)\n",
    "Xv = Xv.iloc[order].reset_index(drop=True)\n",
    "yv = yv[order]\n",
    "tv = tv.iloc[order].reset_index(drop=True)\n",
    "\n",
    "cut = int(0.85 * len(Xv))  # last 15% = lockbox\n",
    "X_dev, y_dev, t_dev = Xv.iloc[:cut], yv[:cut], tv.iloc[:cut]\n",
    "X_lock, y_lock, t_lock = Xv.iloc[cut:], yv[cut:], tv.iloc[cut:]\n",
    "\n",
    "print(\"DEV  :\", len(X_dev), \"fail_rate=\", y_dev.mean(), t_dev.min(), \"->\", t_dev.max())\n",
    "print(\"LOCK :\", len(X_lock), \"fail_rate=\", y_lock.mean(), t_lock.min(), \"->\", t_lock.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73abe8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>k</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>BER_mean</th>\n",
       "      <th>BER_std</th>\n",
       "      <th>True+_mean</th>\n",
       "      <th>True-_mean</th>\n",
       "      <th>threshold_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F-test</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474484</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>0.220808</td>\n",
       "      <td>0.830223</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F-test</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.482326</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.250101</td>\n",
       "      <td>0.785247</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Welch-t</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.093339</td>\n",
       "      <td>0.183434</td>\n",
       "      <td>0.844966</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Welch-t</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.485929</td>\n",
       "      <td>0.071888</td>\n",
       "      <td>0.173737</td>\n",
       "      <td>0.854405</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F-test</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.490893</td>\n",
       "      <td>0.067248</td>\n",
       "      <td>0.190505</td>\n",
       "      <td>0.827708</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Welch-t</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.491030</td>\n",
       "      <td>0.058379</td>\n",
       "      <td>0.216364</td>\n",
       "      <td>0.801576</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Welch-t</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>0.499759</td>\n",
       "      <td>0.050552</td>\n",
       "      <td>0.180404</td>\n",
       "      <td>0.820079</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Welch-t</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.508505</td>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.107071</td>\n",
       "      <td>0.875920</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F-test</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.513874</td>\n",
       "      <td>0.061958</td>\n",
       "      <td>0.076364</td>\n",
       "      <td>0.895889</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F-test</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>0.521794</td>\n",
       "      <td>0.095969</td>\n",
       "      <td>0.234545</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method   k  n_splits  BER_mean   BER_std  True+_mean  True-_mean  \\\n",
       "0   F-test  10         5  0.474484  0.027524    0.220808    0.830223   \n",
       "1   F-test  60         5  0.482326  0.072289    0.250101    0.785247   \n",
       "2  Welch-t  10         5  0.485800  0.093339    0.183434    0.844966   \n",
       "3  Welch-t  60         5  0.485929  0.071888    0.173737    0.854405   \n",
       "4   F-test  40         5  0.490893  0.067248    0.190505    0.827708   \n",
       "5  Welch-t  20         5  0.491030  0.058379    0.216364    0.801576   \n",
       "6  Welch-t  80         5  0.499759  0.050552    0.180404    0.820079   \n",
       "7  Welch-t  40         5  0.508505  0.083470    0.107071    0.875920   \n",
       "8   F-test  20         5  0.513874  0.061958    0.076364    0.895889   \n",
       "9   F-test  80         5  0.521794  0.095969    0.234545    0.721867   \n",
       "\n",
       "   threshold_median  \n",
       "0             0.425  \n",
       "1             0.400  \n",
       "2             0.425  \n",
       "3             0.425  \n",
       "4             0.400  \n",
       "5             0.400  \n",
       "6             0.425  \n",
       "7             0.450  \n",
       "8             0.450  \n",
       "9             0.350  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected config: {'method': 'F-test', 'k': 10, 'n_splits': 5, 'BER_mean': 0.47448440457077545, 'BER_std': 0.027523696525041736, 'True+_mean': 0.22080808080803957, 'True-_mean': 0.8302231100504095, 'threshold_median': 0.42499999999999993}\n"
     ]
    }
   ],
   "source": [
    "def anchored_splits(n, min_train, test_size, step):\n",
    "    out = []\n",
    "    tr_end = min_train\n",
    "    while tr_end + test_size <= n:\n",
    "        out.append((0, tr_end, tr_end, tr_end + test_size))\n",
    "        tr_end += step\n",
    "    return out\n",
    "\n",
    "\n",
    "def best_threshold_by_ber(y_true, p_true, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 37)\n",
    "    best_t, best_ber = 0.5, np.inf\n",
    "    best_tpr, best_tnr = 0.0, 0.0\n",
    "    for t in grid:\n",
    "        pred = (p_true >= t).astype(int)\n",
    "        ber, tpr, tnr = ber_tpr_tnr(y_true, pred)\n",
    "        if (ber < best_ber) or (np.isclose(ber, best_ber) and tpr > best_tpr):\n",
    "            best_t, best_ber, best_tpr, best_tnr = float(t), float(ber), float(tpr), float(tnr)\n",
    "    return best_t, best_ber, best_tpr, best_tnr\n",
    "\n",
    "\n",
    "def build_pipe(method, k, random_state=42):\n",
    "    if method == \"F-test\":\n",
    "        sel = SelectKBest(score_func=f_classif, k=k)\n",
    "    elif method == \"Welch-t\":\n",
    "        sel = WelchTSelector(k=k)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'F-test' or 'Welch-t'\")\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"drop_all_nan\", DropAllNaNCols()),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"sel\", sel),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=3000,\n",
    "            random_state=random_state\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1) DEV-only time-aware tuning\n",
    "# -------------------------\n",
    "methods = [\"F-test\", \"Welch-t\"]\n",
    "k_grid = [10, 20, 40, 60, 80]\n",
    "\n",
    "n_dev = len(X_dev)\n",
    "inner_splits = anchored_splits(\n",
    "    n=n_dev,\n",
    "    min_train=max(300, int(0.50 * n_dev)),\n",
    "    test_size=max(120, int(0.15 * n_dev)),\n",
    "    step=max(40, int(0.15 * n_dev) // 2),\n",
    ")\n",
    "\n",
    "tune_rows = []\n",
    "\n",
    "for method in methods:\n",
    "    for k in k_grid:\n",
    "        fold_rows = []\n",
    "        for sid, (tr_s, tr_e, va_s, va_e) in enumerate(inner_splits, start=1):\n",
    "            Xtr, ytr = X_dev.iloc[tr_s:tr_e], y_dev[tr_s:tr_e]\n",
    "            Xva, yva = X_dev.iloc[va_s:va_e], y_dev[va_s:va_e]\n",
    "\n",
    "            if len(np.unique(ytr)) < 2 or len(np.unique(yva)) < 2:\n",
    "                continue\n",
    "\n",
    "            pipe = build_pipe(method=method, k=k, random_state=42)\n",
    "            pipe.fit(Xtr, ytr)\n",
    "\n",
    "            # tune threshold on this fold's train only\n",
    "            p_tr = pipe.predict_proba(Xtr)[:, 1]\n",
    "            th, tr_ber, _, _ = best_threshold_by_ber(ytr, p_tr)\n",
    "\n",
    "            # evaluate on this fold's val using tuned threshold\n",
    "            p_va = pipe.predict_proba(Xva)[:, 1]\n",
    "            pred_va = (p_va >= th).astype(int)\n",
    "            va_ber, va_tpr, va_tnr = ber_tpr_tnr(yva, pred_va)\n",
    "\n",
    "            fold_rows.append({\n",
    "                \"method\": method,\n",
    "                \"k\": k,\n",
    "                \"split_id\": sid,\n",
    "                \"threshold\": th,\n",
    "                \"val_BER\": va_ber,\n",
    "                \"val_True+\": va_tpr,\n",
    "                \"val_True-\": va_tnr,\n",
    "            })\n",
    "\n",
    "        if fold_rows:\n",
    "            df = pd.DataFrame(fold_rows)\n",
    "            tune_rows.append({\n",
    "                \"method\": method,\n",
    "                \"k\": k,\n",
    "                \"n_splits\": len(df),\n",
    "                \"BER_mean\": df[\"val_BER\"].mean(),\n",
    "                \"BER_std\": df[\"val_BER\"].std(),\n",
    "                \"True+_mean\": df[\"val_True+\"].mean(),\n",
    "                \"True-_mean\": df[\"val_True-\"].mean(),\n",
    "                \"threshold_median\": df[\"threshold\"].median(),\n",
    "            })\n",
    "\n",
    "tune_summary = pd.DataFrame(tune_rows).sort_values(\n",
    "    [\"BER_mean\", \"True+_mean\"], ascending=[True, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "display(tune_summary)\n",
    "\n",
    "best = tune_summary.iloc[0].to_dict()\n",
    "print(\"Selected config:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4304e6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final threshold from full DEV: 0.49999999999999994\n",
      "DEV metrics @threshold: {'BER': 0.28652273888605406, 'True+': 0.715789473684203, 'True-': 0.7111650485436888}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 2) Fit selected config on full DEV\n",
    "# -------------------------\n",
    "best_method = best[\"method\"]\n",
    "best_k = int(best[\"k\"])\n",
    "best_threshold = float(best[\"threshold_median\"])\n",
    "\n",
    "final_pipe = build_pipe(method=best_method, k=best_k, random_state=42)\n",
    "final_pipe.fit(X_dev, y_dev)\n",
    "\n",
    "# Optional: re-tune threshold on full DEV train probs (recommended)\n",
    "p_dev = final_pipe.predict_proba(X_dev)[:, 1]\n",
    "best_threshold, dev_ber, dev_tpr, dev_tnr = best_threshold_by_ber(y_dev, p_dev)\n",
    "\n",
    "print(\"\\nFinal threshold from full DEV:\", best_threshold)\n",
    "print(\"DEV metrics @threshold:\", {\"BER\": dev_ber, \"True+\": dev_tpr, \"True-\": dev_tnr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bef1972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>k</th>\n",
       "      <th>threshold</th>\n",
       "      <th>LOCK_BER</th>\n",
       "      <th>LOCK_True+</th>\n",
       "      <th>LOCK_True-</th>\n",
       "      <th>DEV_n</th>\n",
       "      <th>LOCK_n</th>\n",
       "      <th>DEV_fail_rate</th>\n",
       "      <th>LOCK_fail_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F-test</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.377386</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.911894</td>\n",
       "      <td>1331</td>\n",
       "      <td>236</td>\n",
       "      <td>0.071375</td>\n",
       "      <td>0.038136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   method   k  threshold  LOCK_BER  LOCK_True+  LOCK_True-  DEV_n  LOCK_n  \\\n",
       "0  F-test  10        0.5  0.377386    0.333333    0.911894   1331     236   \n",
       "\n",
       "   DEV_fail_rate  LOCK_fail_rate  \n",
       "0       0.071375        0.038136  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 3) One-time LOCKBOX evaluation\n",
    "# -------------------------\n",
    "p_lock = final_pipe.predict_proba(X_lock)[:, 1]\n",
    "pred_lock = (p_lock >= best_threshold).astype(int)\n",
    "lock_ber, lock_tpr, lock_tnr = ber_tpr_tnr(y_lock, pred_lock)\n",
    "\n",
    "lock_result = pd.DataFrame([{\n",
    "    \"method\": best_method,\n",
    "    \"k\": best_k,\n",
    "    \"threshold\": best_threshold,\n",
    "    \"LOCK_BER\": lock_ber,\n",
    "    \"LOCK_True+\": lock_tpr,\n",
    "    \"LOCK_True-\": lock_tnr,\n",
    "    \"DEV_n\": len(X_dev),\n",
    "    \"LOCK_n\": len(X_lock),\n",
    "    \"DEV_fail_rate\": float(np.mean(y_dev)),\n",
    "    \"LOCK_fail_rate\": float(np.mean(y_lock)),\n",
    "}])\n",
    "\n",
    "display(lock_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f53a823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_splits</th>\n",
       "      <th>mean_delta</th>\n",
       "      <th>median_delta</th>\n",
       "      <th>ci95_low</th>\n",
       "      <th>ci95_med_boot</th>\n",
       "      <th>ci95_high</th>\n",
       "      <th>sign_test_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BER (Welch - F)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.038381</td>\n",
       "      <td>-0.046333</td>\n",
       "      <td>-0.003472</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>0.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True+ (Welch - F)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.053815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.142580</td>\n",
       "      <td>-0.051955</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True- (Welch - F)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.056746</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.057272</td>\n",
       "      <td>0.103528</td>\n",
       "      <td>0.289062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   n_splits  mean_delta  median_delta  ci95_low  \\\n",
       "BER (Welch - F)         8.0   -0.001465     -0.038381 -0.046333   \n",
       "True+ (Welch - F)       8.0   -0.053815      0.000000 -0.142580   \n",
       "True- (Welch - F)       8.0    0.056746      0.077730  0.005832   \n",
       "\n",
       "                   ci95_med_boot  ci95_high  sign_test_pvalue  \n",
       "BER (Welch - F)        -0.003472   0.056035          0.726562  \n",
       "True+ (Welch - F)      -0.051955   0.019717          1.000000  \n",
       "True- (Welch - F)       0.057272   0.103528          0.289062  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import comb\n",
    "\n",
    "def bootstrap_mean_ci(x, n_boot=20000, alpha=0.05, seed=42):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    boot = rng.choice(x, size=(n_boot, len(x)), replace=True).mean(axis=1)\n",
    "    lo = np.percentile(boot, 100 * alpha / 2)\n",
    "    md = np.percentile(boot, 50)\n",
    "    hi = np.percentile(boot, 100 * (1 - alpha / 2))\n",
    "    return float(lo), float(md), float(hi)\n",
    "\n",
    "def sign_test_pvalue(d):\n",
    "    # two-sided sign test for paired deltas\n",
    "    d = np.asarray(d, dtype=float)\n",
    "    wins = int((d < 0).sum())   # \"Welch better\" for BER delta if negative\n",
    "    losses = int((d > 0).sum())\n",
    "    n = wins + losses\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    k = min(wins, losses)\n",
    "    p_one = sum(comb(n, i) for i in range(k + 1)) / (2 ** n)\n",
    "    return min(1.0, 2 * p_one)\n",
    "\n",
    "def paired_delta(metric, lower_is_better):\n",
    "    pv = tuned_df.pivot(index=\"split_id\", columns=\"method\", values=metric).dropna()\n",
    "    d = pv[\"Welch-t\"] - pv[\"F-test\"]\n",
    "    # For BER: negative delta favors Welch-t\n",
    "    # For True+/True-: positive delta favors Welch-t\n",
    "    lo, md, hi = bootstrap_mean_ci(d.values)\n",
    "    p = sign_test_pvalue(d.values if lower_is_better else -d.values)\n",
    "    return pd.Series({\n",
    "        \"n_splits\": len(d),\n",
    "        \"mean_delta\": d.mean(),\n",
    "        \"median_delta\": d.median(),\n",
    "        \"ci95_low\": lo,\n",
    "        \"ci95_med_boot\": md,\n",
    "        \"ci95_high\": hi,\n",
    "        \"sign_test_pvalue\": p\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"BER (Welch - F)\": paired_delta(\"outer_BER\", lower_is_better=True),\n",
    "    \"True+ (Welch - F)\": paired_delta(\"outer_True+\", lower_is_better=False),\n",
    "    \"True- (Welch - F)\": paired_delta(\"outer_True-\", lower_is_better=False),\n",
    "}).T\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ad664d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outer_BER</th>\n",
       "      <th>outer_True+</th>\n",
       "      <th>outer_True-</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F-test</th>\n",
       "      <td>0.470594</td>\n",
       "      <td>0.303425</td>\n",
       "      <td>0.755387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welch-t</th>\n",
       "      <td>0.469129</td>\n",
       "      <td>0.249609</td>\n",
       "      <td>0.812133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         outer_BER  outer_True+  outer_True-\n",
       "method                                      \n",
       "F-test    0.470594     0.303425     0.755387\n",
       "Welch-t   0.469129     0.249609     0.812133"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_df.groupby(\"method\")[[\"outer_BER\",\"outer_True+\",\"outer_True-\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c48b79cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final threshold from full DEV: 0.44999999999999996\n",
      "DEV metrics @threshold: {'BER': 0.3119826264690897, 'True+': 0.7789473684210445, 'True-': 0.5970873786407762}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 2) Fit selected config on full DEV\n",
    "# -------------------------\n",
    "best_method = best[\"method\"]\n",
    "best_k = int(best[\"k\"])\n",
    "best_threshold = float(best[\"threshold_median\"])\n",
    "\n",
    "final_pipe = build_pipe(method=\"Welch-t\", k=best_k, random_state=42)\n",
    "final_pipe.fit(X_dev, y_dev)\n",
    "\n",
    "# Optional: re-tune threshold on full DEV train probs (recommended)\n",
    "p_dev = final_pipe.predict_proba(X_dev)[:, 1]\n",
    "best_threshold, dev_ber, dev_tpr, dev_tnr = best_threshold_by_ber(y_dev, p_dev)\n",
    "\n",
    "print(\"\\nFinal threshold from full DEV:\", best_threshold)\n",
    "print(\"DEV metrics @threshold:\", {\"BER\": dev_ber, \"True+\": dev_tpr, \"True-\": dev_tnr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb8482cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>k</th>\n",
       "      <th>threshold</th>\n",
       "      <th>LOCK_BER</th>\n",
       "      <th>LOCK_True+</th>\n",
       "      <th>LOCK_True-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F-test</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.377386</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.911894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welch-t</td>\n",
       "      <td>10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.406021</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.854626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method   k  threshold  LOCK_BER  LOCK_True+  LOCK_True-\n",
       "0   F-test  10       0.50  0.377386    0.333333    0.911894\n",
       "1  Welch-t  10       0.45  0.406021    0.333333    0.854626"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lockbox eval helper\n",
    "def eval_lockbox(method, k, threshold):\n",
    "    pipe = build_pipe(method=method, k=k, random_state=42)\n",
    "    pipe.fit(X_dev, y_dev)  # fit on DEV only\n",
    "    p = pipe.predict_proba(X_lock)[:, 1]\n",
    "    pred = (p >= threshold).astype(int)\n",
    "    ber, tpr, tnr = ber_tpr_tnr(y_lock, pred)\n",
    "    return {\"method\": method, \"k\": k, \"threshold\": threshold,\n",
    "            \"LOCK_BER\": ber, \"LOCK_True+\": tpr, \"LOCK_True-\": tnr}\n",
    "\n",
    "# example thresholds from your DEV tuning medians\n",
    "lock_f = eval_lockbox(\"F-test\", 10, 0.5)   # or 0.50 if frozen earlier\n",
    "lock_w = eval_lockbox(\"Welch-t\", 10, 0.45)  # use your frozen DEV-only threshold\n",
    "\n",
    "pd.DataFrame([lock_f, lock_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca7af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
